{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5bUWT9PbE2y"
      },
      "source": [
        "# Analyse des sentiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bohe_56hbQ9q"
      },
      "source": [
        "Dans ce projet, nous allons utiliser un ensemble de [données Kaggle](https://www.kaggle.com/kazanova/sentiment140) pour l'analyse des sentiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_tkEBNpbcnK"
      },
      "source": [
        "# Importation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyp3YYYmbn8k"
      },
      "source": [
        "Ajoutez un raccourci de ce dossier à votre google drive :\n",
        "\n",
        "https://drive.google.com/drive/folders/1uj-BnUzSHJOHuojQ9q8q53DN0EGiPpcl?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFjOtn0obEl1",
        "outputId": "df066108-801c-4349-89b1-f78c3146b6cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQZedNAMby-0"
      },
      "source": [
        "# Importation des packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-8Q64rmaR0L",
        "outputId": "fa616810-141b-44ba-9a4a-ec4dad902f25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Import Regex to clean up tweets\n",
        "import re\n",
        "\n",
        "import nltk, string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "# Get Reviews\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Get Tweets\n",
        "import httplib2\n",
        "import requests\n",
        "import urllib3\n",
        "from drive.MyDrive.RNN_sentiment_dataset.random_tweets import *\n",
        "\n",
        "# TF IDF Imports\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import csc_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from joblib import dump, load\n",
        "import torch as torch\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "from torchsummary import summary"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random_tweets imported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMN7fVescdmV"
      },
      "source": [
        "# Import du dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6BecGufb26s"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/RNN_sentiment_dataset/tweets.csv',encoding='latin',usecols=[0, 5], # to take only 2 useful columns\n",
        "                 names=[\"label\",\"tweet\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPEG3XKecn7G"
      },
      "source": [
        "Dans ces données, nous avons y = 0 pour un sentiment négatif et y = 4 pour un sentiment positif.\n",
        "\n",
        "Nous ne garderons que le sentiment positif et négatif et transformerons y pour obtenir 0 pour un sentiment négatif et 1 pour un sentiment positif."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeEP8DU6dNPu"
      },
      "source": [
        "df['label'].replace([4, 0],[1, 0], inplace=True) # Replace 0 and 4 by 0 and 1 to clarify"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "DT5-hzBkhQRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2skzLFQPdW48"
      },
      "source": [
        "# Prétraitements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcy7VAOtdRfv"
      },
      "source": [
        "  print(df.head(25))\n",
        "  len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pakc8WAhdUCG"
      },
      "source": [
        "Nous pouvons voir que les tweets contiennent des mentions, des urls, etc. qui ne sont pas utiles pour le modèle de langage.\n",
        "\n",
        "Nous devons donc nettoyer leur contenu."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_df = df.iloc[:10000, :]"
      ],
      "metadata": {
        "id": "-_PdsdkvhO_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D98xTSRbdxU5"
      },
      "source": [
        "## Nettoyer les tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBHJagcUd8JQ"
      },
      "source": [
        "Je crée une fonction pour nettoyer les tweets. Les contractions sont séparées, les caractères spéciaux sont supprimés, ainsi que les URL, les mentions, les mots trop courts et les mots vides."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN0WT1PUd4cm"
      },
      "source": [
        "def clean(tweet):\n",
        "\n",
        "    # Contractions\n",
        "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
        "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
        "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
        "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
        "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
        "    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
        "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
        "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
        "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
        "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
        "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
        "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
        "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
        "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
        "    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
        "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
        "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
        "    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
        "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
        "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
        "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
        "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
        "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
        "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
        "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
        "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
        "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
        "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
        "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
        "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
        "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
        "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
        "    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
        "    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
        "    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
        "    tweet = re.sub(r\"youve\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"donå«t\", \"do not\", tweet)\n",
        "\n",
        "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
        "    tweet = re.sub(r\"yrs\", \"years\", tweet)\n",
        "    tweet = re.sub(r\"hrs\", \"hours\", tweet)\n",
        "    tweet = re.sub(r\"2morow|2moro\", \"tomorrow\", tweet)\n",
        "    tweet = re.sub(r\"2day\", \"today\", tweet)\n",
        "    tweet = re.sub(r\"4got|4gotten\", \"forget\", tweet)\n",
        "    tweet = re.sub(r\"b-day|bday\", \"b-day\", tweet)\n",
        "    tweet = re.sub(r\"mother's\", \"mother\", tweet)\n",
        "    tweet = re.sub(r\"mom's\", \"mom\", tweet)\n",
        "    tweet = re.sub(r\"dad's\", \"dad\", tweet)\n",
        "    tweet = re.sub(r\"hahah|hahaha|hahahaha\", \"haha\", tweet)\n",
        "    tweet = re.sub(r\"lmao|lolz|rofl\", \"lol\", tweet)\n",
        "    tweet = re.sub(r\"thanx|thnx\", \"thanks\", tweet)\n",
        "    tweet = re.sub(r\"goood\", \"good\", tweet)\n",
        "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
        "    tweet = re.sub(r\"some1\", \"someone\", tweet)\n",
        "    # Character entity references\n",
        "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
        "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
        "    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n",
        "    # Typos, slang and informal abbreviations\n",
        "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
        "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
        "    tweet = re.sub(r\"<3\", \"love\", tweet)\n",
        "    # Urls\n",
        "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
        "    # Numbers\n",
        "    tweet = re.sub(r'[0-9]', '', tweet)\n",
        "    # Eliminating the mentions\n",
        "    tweet = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", tweet)\n",
        "    # Remove punctuation and special chars (keep '!')\n",
        "    for p in string.punctuation.replace('!', ''):\n",
        "        tweet = tweet.replace(p, '')\n",
        "\n",
        "    # ... and ..\n",
        "    tweet = tweet.replace('...', ' ... ')\n",
        "    if '...' not in tweet:\n",
        "        tweet = tweet.replace('..', ' ... ')\n",
        "\n",
        "    # join back\n",
        "    #tweet = ' '.join(tweet)\n",
        "\n",
        "\n",
        "    return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93unwggneKLH"
      },
      "source": [
        "Les abréviations seront remplacées par leur équivalent complet grâce à ce dictionnaire d'abréviations et à la fonction `convert_abbrev_in_text` associée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95WVVnchd6KK"
      },
      "source": [
        "variable_name = \"\"\n",
        "abbreviations = {\n",
        "    \"$\" : \" dollar \",\n",
        "    \"€\" : \" euro \",\n",
        "    \"4ao\" : \"for adults only\",\n",
        "    \"a.m\" : \"before midday\",\n",
        "    \"a3\" : \"anytime anywhere anyplace\",\n",
        "    \"aamof\" : \"as a matter of fact\",\n",
        "    \"acct\" : \"account\",\n",
        "    \"adih\" : \"another day in hell\",\n",
        "    \"afaic\" : \"as far as i am concerned\",\n",
        "    \"afaict\" : \"as far as i can tell\",\n",
        "    \"afaik\" : \"as far as i know\",\n",
        "    \"afair\" : \"as far as i remember\",\n",
        "    \"afk\" : \"away from keyboard\",\n",
        "    \"app\" : \"application\",\n",
        "    \"approx\" : \"approximately\",\n",
        "    \"apps\" : \"applications\",\n",
        "    \"asap\" : \"as soon as possible\",\n",
        "    \"asl\" : \"age, sex, location\",\n",
        "    \"atk\" : \"at the keyboard\",\n",
        "    \"ave.\" : \"avenue\",\n",
        "    \"aymm\" : \"are you my mother\",\n",
        "    \"ayor\" : \"at your own risk\",\n",
        "    \"b&b\" : \"bed and breakfast\",\n",
        "    \"b+b\" : \"bed and breakfast\",\n",
        "    \"b.c\" : \"before christ\",\n",
        "    \"b2b\" : \"business to business\",\n",
        "    \"b2c\" : \"business to customer\",\n",
        "    \"b4\" : \"before\",\n",
        "    \"b4n\" : \"bye for now\",\n",
        "    \"b@u\" : \"back at you\",\n",
        "    \"bae\" : \"before anyone else\",\n",
        "    \"bak\" : \"back at keyboard\",\n",
        "    \"bbbg\" : \"bye bye be good\",\n",
        "    \"bbc\" : \"british broadcasting corporation\",\n",
        "    \"bbias\" : \"be back in a second\",\n",
        "    \"bbl\" : \"be back later\",\n",
        "    \"bbs\" : \"be back soon\",\n",
        "    \"be4\" : \"before\",\n",
        "    \"bfn\" : \"bye for now\",\n",
        "    \"blvd\" : \"boulevard\",\n",
        "    \"bout\" : \"about\",\n",
        "    \"brb\" : \"be right back\",\n",
        "    \"bros\" : \"brothers\",\n",
        "    \"brt\" : \"be right there\",\n",
        "    \"bsaaw\" : \"big smile and a wink\",\n",
        "    \"btw\" : \"by the way\",\n",
        "    \"bwl\" : \"bursting with laughter\",\n",
        "    \"c/o\" : \"care of\",\n",
        "    \"cet\" : \"central european time\",\n",
        "    \"cf\" : \"compare\",\n",
        "    \"cia\" : \"central intelligence agency\",\n",
        "    \"csl\" : \"can not stop laughing\",\n",
        "    \"cu\" : \"see you\",\n",
        "    \"cul8r\" : \"see you later\",\n",
        "    \"cv\" : \"curriculum vitae\",\n",
        "    \"cwot\" : \"complete waste of time\",\n",
        "    \"cya\" : \"see you\",\n",
        "    \"cyt\" : \"see you tomorrow\",\n",
        "    \"dae\" : \"does anyone else\",\n",
        "    \"dbmib\" : \"do not bother me i am busy\",\n",
        "    \"diy\" : \"do it yourself\",\n",
        "    \"dm\" : \"direct message\",\n",
        "    \"dwh\" : \"during work hours\",\n",
        "    \"e123\" : \"easy as one two three\",\n",
        "    \"eet\" : \"eastern european time\",\n",
        "    \"eg\" : \"example\",\n",
        "    \"embm\" : \"early morning business meeting\",\n",
        "    \"encl\" : \"enclosed\",\n",
        "    \"encl.\" : \"enclosed\",\n",
        "    \"etc\" : \"and so on\",\n",
        "    \"faq\" : \"frequently asked questions\",\n",
        "    \"fawc\" : \"for anyone who cares\",\n",
        "    \"fb\" : \"facebook\",\n",
        "    \"fc\" : \"fingers crossed\",\n",
        "    \"fig\" : \"figure\",\n",
        "    \"fimh\" : \"forever in my heart\",\n",
        "    \"ft.\" : \"feet\",\n",
        "    \"ft\" : \"featuring\",\n",
        "    \"ftl\" : \"for the loss\",\n",
        "    \"ftw\" : \"for the win\",\n",
        "    \"fwiw\" : \"for what it is worth\",\n",
        "    \"fyi\" : \"for your information\",\n",
        "    \"g9\" : \"genius\",\n",
        "    \"gahoy\" : \"get a hold of yourself\",\n",
        "    \"gal\" : \"get a life\",\n",
        "    \"gcse\" : \"general certificate of secondary education\",\n",
        "    \"gfn\" : \"gone for now\",\n",
        "    \"gg\" : \"good game\",\n",
        "    \"gl\" : \"good luck\",\n",
        "    \"glhf\" : \"good luck have fun\",\n",
        "    \"gmt\" : \"greenwich mean time\",\n",
        "    \"gmta\" : \"great minds think alike\",\n",
        "    \"gn\" : \"good night\",\n",
        "    \"g.o.a.t\" : \"greatest of all time\",\n",
        "    \"goat\" : \"greatest of all time\",\n",
        "    \"goi\" : \"get over it\",\n",
        "    \"gps\" : \"global positioning system\",\n",
        "    \"gr8\" : \"great\",\n",
        "    \"gratz\" : \"congratulations\",\n",
        "    \"gyal\" : \"girl\",\n",
        "    \"h&c\" : \"hot and cold\",\n",
        "    \"hp\" : \"horsepower\",\n",
        "    \"hr\" : \"hour\",\n",
        "    \"hrh\" : \"his royal highness\",\n",
        "    \"ht\" : \"height\",\n",
        "    \"ibrb\" : \"i will be right back\",\n",
        "    \"ic\" : \"i see\",\n",
        "    \"icq\" : \"i seek you\",\n",
        "    \"icymi\" : \"in case you missed it\",\n",
        "    \"idc\" : \"i do not care\",\n",
        "    \"idgadf\" : \"i do not give a damn fuck\",\n",
        "    \"idgaf\" : \"i do not give a fuck\",\n",
        "    \"idk\" : \"i do not know\",\n",
        "    \"ie\" : \"that is\",\n",
        "    \"i.e\" : \"that is\",\n",
        "    \"ifyp\" : \"i feel your pain\",\n",
        "    \"IG\" : \"instagram\",\n",
        "    \"iirc\" : \"if i remember correctly\",\n",
        "    \"ilu\" : \"i love you\",\n",
        "    \"ily\" : \"i love you\",\n",
        "    \"imho\" : \"in my humble opinion\",\n",
        "    \"imo\" : \"in my opinion\",\n",
        "    \"imu\" : \"i miss you\",\n",
        "    \"iow\" : \"in other words\",\n",
        "    \"irl\" : \"in real life\",\n",
        "    \"j4f\" : \"just for fun\",\n",
        "    \"jic\" : \"just in case\",\n",
        "    \"jk\" : \"just kidding\",\n",
        "    \"jsyk\" : \"just so you know\",\n",
        "    \"l8r\" : \"later\",\n",
        "    \"lb\" : \"pound\",\n",
        "    \"lbs\" : \"pounds\",\n",
        "    \"ldr\" : \"long distance relationship\",\n",
        "    \"lmao\" : \"laugh my ass off\",\n",
        "    \"lmfao\" : \"laugh my fucking ass off\",\n",
        "    \"lol\" : \"laughing out loud\",\n",
        "    \"ltd\" : \"limited\",\n",
        "    \"ltns\" : \"long time no see\",\n",
        "    \"m8\" : \"mate\",\n",
        "    \"mf\" : \"motherfucker\",\n",
        "    \"mfs\" : \"motherfuckers\",\n",
        "    \"mfw\" : \"my face when\",\n",
        "    \"mofo\" : \"motherfucker\",\n",
        "    \"mph\" : \"miles per hour\",\n",
        "    \"mr\" : \"mister\",\n",
        "    \"mrw\" : \"my reaction when\",\n",
        "    \"ms\" : \"miss\",\n",
        "    \"mte\" : \"my thoughts exactly\",\n",
        "    \"nagi\" : \"not a good idea\",\n",
        "    \"nbc\" : \"national broadcasting company\",\n",
        "    \"nbd\" : \"not big deal\",\n",
        "    \"nfs\" : \"not for sale\",\n",
        "    \"ngl\" : \"not going to lie\",\n",
        "    \"nhs\" : \"national health service\",\n",
        "    \"nrn\" : \"no reply necessary\",\n",
        "    \"nsfl\" : \"not safe for life\",\n",
        "    \"nsfw\" : \"not safe for work\",\n",
        "    \"nth\" : \"nice to have\",\n",
        "    \"nvr\" : \"never\",\n",
        "    \"nyc\" : \"new york city\",\n",
        "    \"oc\" : \"original content\",\n",
        "    \"og\" : \"original\",\n",
        "    \"ohp\" : \"overhead projector\",\n",
        "    \"oic\" : \"oh i see\",\n",
        "    \"omdb\" : \"over my dead body\",\n",
        "    \"omg\" : \"oh my god\",\n",
        "    \"omw\" : \"on my way\",\n",
        "    \"p.a\" : \"per annum\",\n",
        "    \"p.m\" : \"after midday\",\n",
        "    \"pm\" : \"prime minister\",\n",
        "    \"poc\" : \"people of color\",\n",
        "    \"pov\" : \"point of view\",\n",
        "    \"pp\" : \"pages\",\n",
        "    \"ppl\" : \"people\",\n",
        "    \"prw\" : \"parents are watching\",\n",
        "    \"ps\" : \"postscript\",\n",
        "    \"pt\" : \"point\",\n",
        "    \"ptb\" : \"please text back\",\n",
        "    \"pto\" : \"please turn over\",\n",
        "    \"qpsa\" : \"what happens\",\n",
        "    \"ratchet\" : \"rude\",\n",
        "    \"rbtl\" : \"read between the lines\",\n",
        "    \"rlrt\" : \"real life retweet\",\n",
        "    \"rofl\" : \"rolling on the floor laughing\",\n",
        "    \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "    \"rt\" : \"retweet\",\n",
        "    \"ruok\" : \"are you ok\",\n",
        "    \"sfw\" : \"safe for work\",\n",
        "     \"sk8\" : \"skate\",\n",
        "    \"smh\" : \"shake my head\",\n",
        "    \"sq\" : \"square\",\n",
        "    \"srsly\" : \"seriously\",\n",
        "    \"ssdd\" : \"same stuff different day\",\n",
        "    \"tbh\" : \"to be honest\",\n",
        "    \"tbs\" : \"tablespooful\",\n",
        "    \"tbsp\" : \"tablespooful\",\n",
        "    \"tfw\" : \"that feeling when\",\n",
        "    \"thks\" : \"thank you\",\n",
        "    \"tho\" : \"though\",\n",
        "    \"thx\" : \"thank you\",\n",
        "    \"tia\" : \"thanks in advance\",\n",
        "    \"til\" : \"today i learned\",\n",
        "    \"tl;dr\" : \"too long i did not read\",\n",
        "    \"tldr\" : \"too long i did not read\",\n",
        "    \"tmb\" : \"tweet me back\",\n",
        "    \"tntl\" : \"trying not to laugh\",\n",
        "    \"ttyl\" : \"talk to you later\",\n",
        "    \"u\" : \"you\",\n",
        "    \"u2\" : \"you too\",\n",
        "    \"u4e\" : \"yours for ever\",\n",
        "    \"utc\" : \"coordinated universal time\",\n",
        "    \"w/\" : \"with\",\n",
        "    \"w/o\" : \"without\",\n",
        "    \"w8\" : \"wait\",\n",
        "    \"wassup\" : \"what is up\",\n",
        "    \"wb\" : \"welcome back\",\n",
        "    \"wtf\" : \"what the fuck\",\n",
        "    \"wtg\" : \"way to go\",\n",
        "    \"wtpa\" : \"where the party at\",\n",
        "    \"wuf\" : \"where are you from\",\n",
        "    \"wuzup\" : \"what is up\",\n",
        "    \"wywh\" : \"wish you were here\",\n",
        "    \"yd\" : \"yard\",\n",
        "    \"ygtr\" : \"you got that right\",\n",
        "    \"ynk\" : \"you never know\",\n",
        "    \"zzz\" : \"sleeping bored and tired\"\n",
        "}\n",
        "\n",
        "def convert_abbrev_in_text(tweet):\n",
        "    t=[]\n",
        "    words=tweet.split()\n",
        "    t = [abbreviations[w.lower()] if w.lower() in abbreviations.keys() else w for w in words]\n",
        "    return ' '.join(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wy3Wq-aeONJ"
      },
      "source": [
        "La fonction suivante exécute les deux fonctions définies ci-dessus sur un tweet donné :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otc2qVcbeL6B"
      },
      "source": [
        "def prepare_string(tweet):\n",
        "  tweet = clean(tweet)\n",
        "  tweet = convert_abbrev_in_text(tweet)\n",
        "  return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al9EVADbeRsY"
      },
      "source": [
        "Cette étape peut prendre quelques minutes, elle applique la fonction de nettoyage à tous les tweets du corpus de texte et supprime les lignes qui sont vides après le nettoyage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Iq7Gr0ZeQL7"
      },
      "source": [
        "%%time\n",
        "# Apply prepare_string to all rows in 'tweets' column\n",
        "small_df['tweet'] = small_df['tweet'].apply(lambda s : prepare_string(s))\n",
        "\n",
        "# Drop empty values from dataframe\n",
        "small_df['tweet'].replace('', np.nan, inplace=True)\n",
        "small_df.dropna(subset=['tweet'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_df['tweet']"
      ],
      "metadata": {
        "id": "AHnyaDVLqELz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalisation"
      ],
      "metadata": {
        "id": "BMOsRQZ6m1Ww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mettre tout les mots en minuscules."
      ],
      "metadata": {
        "id": "r-9F5mfJy-ZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "small_df['tweet'] = [w.lower() for w in small_df['tweet']]"
      ],
      "metadata": {
        "id": "Ha19qgs9yuwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize"
      ],
      "metadata": {
        "id": "R8tqNo8omDD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TweetTokenizer(strip_handles=True)"
      ],
      "metadata": {
        "id": "ppse4qRjmidU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "small_df['tweet'] = small_df['tweet'].apply(lambda s : tokenizer.tokenize(s))"
      ],
      "metadata": {
        "id": "dRExj6NRmWwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_df['tweet']"
      ],
      "metadata": {
        "id": "fWvuWh1Qzxu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop words"
      ],
      "metadata": {
        "id": "S95jiO4fm6Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "XejNrIqW1y6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for i, s in zip(np.arange(small_df['tweet'].shape[0]), small_df['tweet']):\n",
        "\n",
        "  small_df['tweet'][i] = [w.lower() for w in s if not w in stop_words]"
      ],
      "metadata": {
        "id": "NUWHwUUP2MFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisation du dataframe obtenu"
      ],
      "metadata": {
        "id": "VBz4BxcZ22XF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kon3bKO3eXIc"
      },
      "source": [
        "small_df.head(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jeu de données complet"
      ],
      "metadata": {
        "id": "OzddPzYL6JYq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RQiDkWXeb7d"
      },
      "source": [
        "Le DataFrame résultant est converti en CSV et téléchargé afin d'éviter la réexécution du code précédent qui consomme beaucoup de ressources et de temps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyyYaavmecNj"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/RNN_sentiment_dataset/cleaned_tweets.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFj93f1Eeu7x"
      },
      "source": [
        "Les données sont maintenant prêtes à être soumises aux différentes méthodes de traitement."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "-hBwSRwp588F",
        "outputId": "4c53cd98-1ebf-4be5-cde1-274c3cb7d522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                              tweet\n",
              "0      0       awww bummer shoulda got david carr third day\n",
              "1      0  upset cannot update facebook texting might cry...\n",
              "2      0     dived many times ball managed save rest bounds\n",
              "3      0                   whole body feels itchy like fire\n",
              "4      0                            behaving mad cannot see"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb67d98d-b179-4b60-9213-2e9207deece6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>awww bummer shoulda got david carr third day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>upset cannot update facebook texting might cry...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>dived many times ball managed save rest bounds</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>whole body feels itchy like fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>behaving mad cannot see</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb67d98d-b179-4b60-9213-2e9207deece6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb67d98d-b179-4b60-9213-2e9207deece6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb67d98d-b179-4b60-9213-2e9207deece6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f11cd991-7db6-4317-bcaf-faa9efed950d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f11cd991-7db6-4317-bcaf-faa9efed950d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f11cd991-7db6-4317-bcaf-faa9efed950d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b072kCce8Ip"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUCSoW0Kfg9T"
      },
      "source": [
        "# Using all the data exceeds the RAM capacity of the Notebook\n",
        "corpus_size = int(10000)\n",
        "\n",
        "# Tweets are chosen at the beginning and end of the dataset to have equal parts positive and negative sentiment\n",
        "tweets = [*df['tweet'].values[:int(corpus_size/2)], *df['tweet'].values[-int(corpus_size/2):]]\n",
        "# As well as for the associated targets\n",
        "y = [*df['label'].values[:int(corpus_size/2)], *df['label'].values[-int(corpus_size/2):]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPpVRwFzfHj7"
      },
      "source": [
        "Utilisez la fonction TF-IDF de Sklearn.\n",
        "\n",
        "Aidez-vous de la [doc](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyPyP9t7fTv-"
      },
      "source": [
        "tfIdfVectorizer = TfidfVectorizer()\n",
        "X = tfIdfVectorizer.fit_transform(tweets).toarray()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM_CSNzefvRl"
      },
      "source": [
        "Divisez votre ensemble de données de formation et de test à l'aide de la fonction sklearn.\n",
        "\n",
        "Aidez-vous de la [doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFKso6IbexJP"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.33)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création du générateur"
      ],
      "metadata": {
        "id": "5ctJ05TryuRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création d'un dataset custom adapté à notre problématique."
      ],
      "metadata": {
        "id": "AWNynonqyzzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_train, y_train):\n",
        "        self.input = x_train\n",
        "        self.output = y_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.output)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_input = self.input[idx]\n",
        "        batch_output = self.output[idx]\n",
        "\n",
        "        return batch_input, batch_output"
      ],
      "metadata": {
        "id": "hy3r4YwWuNud"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_training = CustomDataset(torch.from_numpy(np.float32(X_train[:1000])),\n",
        "                                 torch.from_numpy(np.array(np.expand_dims(np.float32(y_train[:1000]), axis=-1))))"
      ],
      "metadata": {
        "id": "xn0O6GJHugEZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilisez la fonction `DataLoader` avec une taille de batch de 2 pour créer le générateur."
      ],
      "metadata": {
        "id": "BT255-D1y5kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_train = torch.utils.data.DataLoader(x_training, 2)"
      ],
      "metadata": {
        "id": "WE0T5OKzuguT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vérification du générateur."
      ],
      "metadata": {
        "id": "pJb4kmnMzAzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataloader_train:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "HhoiWbSeu-wM",
        "outputId": "907cf8fa-c517-46ac-c267-7efcdbd98134",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 13922])\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_testing = CustomDataset(torch.from_numpy(np.float32(X_test)),\n",
        "                                 torch.from_numpy(np.array(np.expand_dims(np.float32(y_test), axis=-1))))"
      ],
      "metadata": {
        "id": "BCZSJWgyvBc1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilisation de la fonction `DataLoader` pour créer le générateur de test, avec une taille de batch de 2."
      ],
      "metadata": {
        "id": "PT4pNYQRzDNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_test = torch.utils.data.DataLoader(x_testing, 2)"
      ],
      "metadata": {
        "id": "9m_9eotpvOZf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vérification du générateur."
      ],
      "metadata": {
        "id": "mSvDbYIazI0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataloader_test:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "VgXIPrqPvRSF",
        "outputId": "085ed2d9-8671-4844-e9ac-dcf15de03293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 13922])\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraînement du modèle"
      ],
      "metadata": {
        "id": "0Kv89EzPzLD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fontion d'entraînement"
      ],
      "metadata": {
        "id": "d1qMRdWozMkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_good_prediction(prediction:float, target:int):\n",
        "  one_hot_prediction = np.where(prediction>0.5, 1, 0)\n",
        "  return np.sum(one_hot_prediction == target)"
      ],
      "metadata": {
        "id": "idBsG0wwtJ_p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step(model:torch.nn.Sequential,\n",
        "         opt:torch.optim,\n",
        "         criterion:torch.nn.modules.loss,\n",
        "         x_train:torch.Tensor,\n",
        "         y_train:torch.Tensor,\n",
        "         metric_function)->tuple:\n",
        "  \"\"\"\n",
        "  Executes a single training step for a PyTorch model.\n",
        "  This function performs a forward pass to compute the model's predictions, calculates\n",
        "  the loss between predictions and actual target values, computes gradients for each\n",
        "  model parameter, and updates the parameters using the optimizer.\n",
        "\n",
        "  Args:\n",
        "      model (torch.nn.Sequential): The PyTorch model to train.\n",
        "      optimizer (torch.optim.Optimizer): Optimizer used to update the model's parameters.\n",
        "      criterion (torch.nn.modules.loss._Loss): Loss function used to compute the error.\n",
        "      x_train (torch.Tensor): Input training data (features).\n",
        "      y_train (torch.Tensor): Ground truth labels or target values for the training data.\n",
        "  Returns:\n",
        "      tuple: The updated model and the computed loss for the current step.\n",
        "  \"\"\"\n",
        "\n",
        "  # Réinitialisez les gradients d'optimizer à zéro avec la méthode 'zero_grad'\n",
        "  opt.zero_grad()\n",
        "\n",
        "  # Calculez les prédiction sur le jeu d'entraînement avec la méthode 'froward'\n",
        "  prediction = model.forward(x_train)\n",
        "\n",
        "  # Calculez l'erreur de prédiction avec 'criterion'\n",
        "  loss = criterion(prediction, y_train)\n",
        "\n",
        "  performance = metric_function(prediction.detach().numpy(), y_train.detach().numpy())\n",
        "\n",
        "  # Calculez les gradients avec la méthode 'backward'\n",
        "  loss.backward()\n",
        "\n",
        "  # Mettre à jour les paramètres du modèle avec la méthode 'step'\n",
        "  opt.step()\n",
        "\n",
        "  return model, loss, performance"
      ],
      "metadata": {
        "id": "tP2jgi2gtZdd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, optimizer, criterion, epoch, trainloader, testloader, metric_function):\n",
        "    epoch = epoch\n",
        "    history_train_loss = []\n",
        "    history_test_loss = []\n",
        "    history_train_metrics = []\n",
        "    history_test_metrics = []\n",
        "\n",
        "    for e in range(epoch) :\n",
        "\n",
        "      train_loss_batch = 0\n",
        "      test_loss_batch = 0\n",
        "      train_metric_batch = 0\n",
        "      test_metric_batch = 0\n",
        "\n",
        "      for images, labels in trainloader:\n",
        "\n",
        "        # mise à jour des poids avec la fonction 'step'\n",
        "        model, train_loss, train_performance = step(model, optimizer, criterion, images, labels, metric_function)\n",
        "\n",
        "        train_loss_batch += train_loss.detach().numpy()\n",
        "\n",
        "        train_metric_batch += train_performance\n",
        "\n",
        "      for images, labels in testloader:\n",
        "\n",
        "        prediction = model.forward(images)\n",
        "\n",
        "        test_loss = criterion(prediction, labels)\n",
        "\n",
        "        test_metric_batch += metric_function(prediction.detach().numpy(), labels.detach().numpy())\n",
        "\n",
        "        test_loss_batch += test_loss.detach().numpy()\n",
        "\n",
        "      train_loss_batch /= len(trainloader.sampler)\n",
        "      test_loss_batch /= len(testloader.sampler)\n",
        "\n",
        "      train_metric_batch /= len(trainloader.sampler)\n",
        "      test_metric_batch /= len(testloader.sampler)\n",
        "\n",
        "      # Sauvegarde des coûts d'entraînement avec append\n",
        "      history_train_loss = np.append(history_train_loss, train_loss_batch)\n",
        "      history_test_loss = np.append(history_test_loss, test_loss_batch)\n",
        "\n",
        "      # Sauvegarde des coûts d'entraînement avec append\n",
        "      history_train_metrics = np.append(history_train_metrics, train_metric_batch)\n",
        "      history_test_metrics = np.append(history_test_metrics, test_metric_batch)\n",
        "\n",
        "      print(f'epoch : {e}/{epoch}')\n",
        "      print('train_loss : '+str(np.squeeze(train_loss_batch))+ ' test_loss : '+str(np.squeeze(test_loss_batch)))\n",
        "      print('train_metric : '+str(np.squeeze(train_metric_batch))+ ' test_metric : '+str(np.squeeze(test_metric_batch)))\n",
        "      print('-------------------------------------------------------------------------------------------------')\n",
        "\n",
        "    return model, history_train_loss, history_test_loss, history_train_metrics, history_test_metrics\n"
      ],
      "metadata": {
        "id": "CqDoQiXQta7S"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialisez le modèle avec la fonction `Sequential` pour obtenir l'architecture suivante :\n",
        "- une couche linéaire avec 64 neurones,\n",
        "- une couche de relu,\n",
        "- une couche linéaire avec 32 neurones,\n",
        "- une couche de relu,\n",
        "- une couche linéaire avec 1 neurone,\n",
        "- une couche Sigmoid."
      ],
      "metadata": {
        "id": "FfDnF2xwzO6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(13922, 64), torch.nn.ReLU(),\n",
        "    torch.nn.Linear(64, 32), torch.nn.ReLU(),\n",
        "    torch.nn.Linear(32, 1), torch.nn.Sigmoid(),\n",
        ")"
      ],
      "metadata": {
        "id": "rKCdsBqWtdkf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilisez la fontion `summary` pour visualisez le modèle."
      ],
      "metadata": {
        "id": "01qmQ-x3z3yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (2,13922), device=(\"cpu\"))"
      ],
      "metadata": {
        "id": "wneK-CTZwZjD",
        "outputId": "c013913b-2aa0-4567-9455-1cf6287bfbe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 2, 64]         891,072\n",
            "              ReLU-2                [-1, 2, 64]               0\n",
            "            Linear-3                [-1, 2, 32]           2,080\n",
            "              ReLU-4                [-1, 2, 32]               0\n",
            "            Linear-5                 [-1, 2, 1]              33\n",
            "           Sigmoid-6                 [-1, 2, 1]               0\n",
            "================================================================\n",
            "Total params: 893,185\n",
            "Trainable params: 893,185\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 3.41\n",
            "Estimated Total Size (MB): 3.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilisez la fonction `BCELoss` comme fonction de coût.\n",
        "\n",
        "Utilisez la fonction `Adam` comme optimizer avec un learning rate de 0.001."
      ],
      "metadata": {
        "id": "sc2QRAKAz5Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "6fhAX_ytw6QA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch=5"
      ],
      "metadata": {
        "id": "wiCEp_Niw6mH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilisez la fonction `fit` pour entraîner le modèle."
      ],
      "metadata": {
        "id": "Ux6mlm7z0CwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, history_train_loss_deep, history_test_loss_deep, history_train_metrics_deep, history_test_metrics_deep = fit(\n",
        "    model, optimizer, criterion, epoch, dataloader_train, dataloader_test, number_of_good_prediction\n",
        ")"
      ],
      "metadata": {
        "id": "tpgzQUAzw23U",
        "outputId": "d3127585-9294-43b0-93a1-8fb6c8792abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0/5\n",
            "train_loss : 0.34012863257527354 test_loss : 0.33348065561767837\n",
            "train_metric : 0.562 test_metric : 0.5695522388059702\n",
            "-------------------------------------------------------------------------------------------------\n",
            "epoch : 1/5\n",
            "train_loss : 0.16744280496239664 test_loss : 0.36717629030082766\n",
            "train_metric : 0.87 test_metric : 0.6571641791044777\n",
            "-------------------------------------------------------------------------------------------------\n",
            "epoch : 2/5\n",
            "train_loss : 0.032648997532902284 test_loss : 0.4534503016868474\n",
            "train_metric : 0.978 test_metric : 0.6483582089552239\n",
            "-------------------------------------------------------------------------------------------------\n",
            "epoch : 3/5\n",
            "train_loss : 0.005794582222632016 test_loss : 0.5104607394763027\n",
            "train_metric : 0.998 test_metric : 0.6482089552238806\n",
            "-------------------------------------------------------------------------------------------------\n",
            "epoch : 4/5\n",
            "train_loss : 0.001847037744395493 test_loss : 0.5678469313307005\n",
            "train_metric : 1.0 test_metric : 0.6492537313432836\n",
            "-------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m6k9TJzg6eL"
      },
      "source": [
        "Calculer la prédiction sur l'ensemble de test avec la fonction `forward`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5BWYCO_g9Zq"
      },
      "source": [
        "predictions = model.forward(x_testing.input)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_hot = np.where(predictions>0.5, 1, 0)"
      ],
      "metadata": {
        "id": "lmD8k9oJ6REB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVyMm31-gUp8"
      },
      "source": [
        "Calculer quelques mesures de performance :\n",
        "- matrice de confusion ([doc](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)) ;\n",
        "- rapport de classification ([doc](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)) ;\n",
        "- accuracy ([doc](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5hO6AHdgTRV",
        "outputId": "8966b189-6bba-4def-8aae-2f2681eed90b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"confusion matric: \\n\", confusion_matrix(x_testing.output, predictions_hot))\n",
        "\n",
        "print(\"classification report: \\n\", classification_report(x_testing.output, predictions_hot))\n",
        "\n",
        "print(\"accuracy_score: \\n\", accuracy_score(x_testing.output, predictions_hot))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matric: \n",
            " [[1962 1428]\n",
            " [ 922 2388]]\n",
            "classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.58      0.63      3390\n",
            "         1.0       0.63      0.72      0.67      3310\n",
            "\n",
            "    accuracy                           0.65      6700\n",
            "   macro avg       0.65      0.65      0.65      6700\n",
            "weighted avg       0.65      0.65      0.65      6700\n",
            "\n",
            "accuracy_score: \n",
            " 0.6492537313432836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0bnQExXNLBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}