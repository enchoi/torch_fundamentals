{"cells":[{"cell_type":"markdown","metadata":{"id":"l9BoIL9veHGz"},"source":["# Importation des packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TfdzOsOUdKwA"},"outputs":[],"source":["import librosa, librosa.display\n","import matplotlib.pyplot as plt\n","import torch as torch\n","from torch.utils.data import Dataset\n","import numpy as np\n","import soundfile as sf\n","from torchsummary import summary"]},{"cell_type":"markdown","metadata":{"id":"O7EA74Ibd9Ps"},"source":["Ajoutez un raccourci de ce dossier à votre google drive :\n","\n","https://drive.google.com/drive/folders/1VJk20mb-W_3sYbz3u6qmiFPquP03Dizc?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V8B7G8nyd7wX"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"y5j3LW145UWa"},"source":["# Importation des données"]},{"cell_type":"markdown","source":["Chemin du son sans le bruit."],"metadata":{"id":"dgXyRQU7E-Yo"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZdbrrYjd_BI"},"outputs":[],"source":["path_without_noise = \"drive/MyDrive/denoising_sound/with_reverb/clean_fileid_44.wav\""]},{"cell_type":"markdown","source":["Utilisez la fonction `load` de librosa pour importer le son sans bruit."],"metadata":{"id":"YEm_cZC0Z2EG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1xjI6L-gMDZ"},"outputs":[],"source":["signal, sr = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9l3WGSSthD0r"},"outputs":[],"source":["signal.shape"]},{"cell_type":"markdown","source":["Chemin du son avec le bruit."],"metadata":{"id":"x_Om_wSzFBdB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rV0EHjbof9Qv"},"outputs":[],"source":["path_with_noise = \"drive/MyDrive/denoising_sound/with_reverb_and_noise/clnsp17_birds_413745_3_snr2_tl-23_fileid_44.wav\""]},{"cell_type":"markdown","source":["Utilisez la fonction `load` de librosa pour importer le son sans bruit."],"metadata":{"id":"_WNVPImfabae"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GuOg67yeh3o"},"outputs":[],"source":["signal_noise, sr_noise = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iG7te3e3hF3N"},"outputs":[],"source":["signal_noise.shape"]},{"cell_type":"markdown","metadata":{"id":"mlUP3wgz5UWc"},"source":["Visualisation des données"]},{"cell_type":"markdown","source":["Utilisez la fonction `waveshow` de librosa pour afficher les deux signales.\n","\n","Challenge : utilisez matplotlib pour afficher les graphiques cotes à cotes."],"metadata":{"id":"Nvk7sIZwaeYx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"t9yTVtZ_gYuv"},"outputs":[],"source":["### Your code ###\n","\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","source":["# Créer le générateur"],"metadata":{"id":"h1IycfE17zXr"}},{"cell_type":"markdown","source":["La classe permettant de créer notre dataset personnalisé."],"metadata":{"id":"BBJj_TtDFXPQ"}},{"cell_type":"code","source":["class CustomImageDataset(Dataset):\n","    def __init__(self, x_train, y_train):\n","        self.img_input = x_train\n","        self.img_output = y_train\n","\n","    def __len__(self):\n","        return len(self.img_output)\n","\n","    def __getitem__(self, idx):\n","        image = self.img_input[idx, :, :]\n","        label = self.img_output[idx, :, :]\n","\n","        return image, label"],"metadata":{"id":"J936_r0yFW9h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nous allons prendre seulement les 40960 informations de la bande son."],"metadata":{"id":"YBKh7aK7FeFA"}},{"cell_type":"code","source":["x_training = CustomImageDataset(torch.from_numpy(np.expand_dims(np.expand_dims(signal_noise[:40960], axis=0), axis=1)),\n","                                 torch.from_numpy(np.expand_dims(np.expand_dims(signal[:40960], axis=0), axis=1)))"],"metadata":{"id":"UPRVXVRw4OaU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la fonction `DataLoader` pour créer le générateur."],"metadata":{"id":"tBecjLQPFlJE"}},{"cell_type":"code","source":["dataloader_train = None"],"metadata":{"id":"79kXqTos4boX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vérifiez que les dimensions correspodent bien avec ce qui est attendu."],"metadata":{"id":"UYFGCiOyFrEO"}},{"cell_type":"code","source":["for x, y in dataloader_train:\n","  print(x.shape)\n","  print(y.shape)\n","\n","  break"],"metadata":{"id":"SyP5j8Em5sfb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaWTgHfd5UWd"},"source":["# Obtenir un sur-entraînement"]},{"cell_type":"markdown","source":["Vous allez entraîner des modèles pour obtenir un débruitage complet du son bruité."],"metadata":{"id":"uLycLEQ3arFz"}},{"cell_type":"markdown","source":["# fonctions d'entraînement"],"metadata":{"id":"r9xZwy9-4DKz"}},{"cell_type":"code","source":["def step(model:torch.nn.Sequential,\n","         opt:torch.optim,\n","         criterion:torch.nn.modules.loss,\n","         x_train:torch.Tensor,\n","         y_train:torch.Tensor)->tuple:\n","  \"\"\"\n","  Executes a single training step for a PyTorch model.\n","  This function performs a forward pass to compute the model's predictions, calculates\n","  the loss between predictions and actual target values, computes gradients for each\n","  model parameter, and updates the parameters using the optimizer.\n","\n","  Args:\n","      model (torch.nn.Sequential): The PyTorch model to train.\n","      optimizer (torch.optim.Optimizer): Optimizer used to update the model's parameters.\n","      criterion (torch.nn.modules.loss._Loss): Loss function used to compute the error.\n","      x_train (torch.Tensor): Input training data (features).\n","      y_train (torch.Tensor): Ground truth labels or target values for the training data.\n","  Returns:\n","      tuple: The updated model and the computed loss for the current step.\n","  \"\"\"\n","\n","  # Réinitialisez les gradients d'optimizer à zéro avec la méthode 'zero_grad'\n","  opt.zero_grad()\n","\n","  # Calculez les prédiction sur le jeu d'entraînement avec la méthode 'froward'\n","  prediction = model.forward(x_train)\n","\n","  # Calculez l'erreur de prédiction avec 'criterion'\n","  loss = criterion(prediction, y_train)\n","\n","  # Calculez les gradients avec la méthode 'backward'\n","  loss.backward()\n","\n","  # Mettre à jour les paramètres du modèle avec la méthode 'step'\n","  opt.step()\n","\n","  return model, loss"],"metadata":{"id":"2GweSYLD4Fh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fit(model, optimizer, criterion, epoch, trainloader):\n","    epoch = epoch\n","    history_train_loss = []\n","\n","    for e in range(epoch) :\n","\n","      train_loss_batch = 0\n","\n","      for images, labels in trainloader:\n","\n","        # mise à jour des poids avec la fonction 'step'\n","        model, train_loss = step(model, optimizer, criterion, images, labels)\n","\n","        train_loss_batch += train_loss.detach().numpy()\n","\n","      train_loss_batch /= len(trainloader.sampler)\n","\n","      # Sauvegarde des coûts d'entraînement avec append\n","      history_train_loss = np.append(history_train_loss, train_loss_batch)\n","\n","      if e % 100==0:\n","        print(f'epoch : {e}/{epoch}')\n","        print('train_loss : '+str(np.squeeze(train_loss_batch)))\n","        print('-------------------------------------------------------------------------------------------------')\n","\n","    return model, history_train_loss, history_test_loss"],"metadata":{"id":"zYXJWgzg4GI6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ApvzENQW5UWd"},"source":["## Première tentative"]},{"cell_type":"markdown","metadata":{"id":"r-yDpz4F5UWd"},"source":["Initialisez un modèle qui vous serivra de baseline."]},{"cell_type":"markdown","source":["Initialiser le modèle suivant:\n","- Utilisez la fonction `conv_block` pour initialiser une couche de convolution en 1 dimension avec 16 filtres et activer par Relu.\n","- Une couche de maxpooling avec une fenêtre de 2 et un stride de 2,\n","- Utilisez la fonction `conv_block` pour initialiser une couche de convolution en 1 dimension avec 32 filtres et activer par Relu.\n","- Une couche de `ConvTranspose` avec 16 filtres, une taille de filtres de 2 et un stride de 2,\n","- Une dernière convolution avec un filtre.\n","\n","Pour ceux modèle vous allez intialisez tous vos composants dans la fonction `__init__` puis les utilisez dans le bonne ordre dans la fonction `forward`.\n","\n","Vous pouvez vous nspirez de la création du modèle via ce [lien](https://medium.com/analytics-vidhya/unet-implementation-in-pytorch-idiot-developer-da40d955f201)\n","\n","N'hésitez pas à demander de l'aide à ChatGPT qui permet d'aider à l'élaboration de ce type d'architecture."],"metadata":{"id":"n12Oe56tbVAl"}},{"cell_type":"code","source":["class UNet(nn.Module):\n","    def __init__(self, in_channels=1, out_channels=1):\n","        super(UNet, self).__init__()\n","\n","        # Encodeur (partie descendante)\n","        self.encoder1 = None\n","\n","        # Couche de réduction de dimension\n","        self.pool = None\n","\n","        # Couche du bas (bottleneck)\n","        self.bottleneck = None\n","\n","        # Décodeur (partie montante)\n","        self.upconv2 = None\n","\n","\n","        self.final_layer = None\n","\n","\n","    def conv_block(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=\"same\"),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        # Encodeur\n","        enc1 = None\n","        pool1 = None\n","\n","        # Bottleneck\n","        bottleneck = None\n","\n","        # Décodeur avec les skip connections\n","        dec2 = None\n","        cat2 = None\n","\n","        # Couche final\n","        output = None\n","\n","        return output"],"metadata":{"id":"o3EhRQJ10s3o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la fonction `UNet` pour initialiser le modèle."],"metadata":{"id":"wU7A_VAZIFnl"}},{"cell_type":"code","source":["model = None"],"metadata":{"id":"gRSkdxpZ3Uls"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la fonction `summary` pour visualisez votre modèle.\n","\n","A noter : Vous ne verrez pas apparaitre vos concatenations dans le summary c'est normal."],"metadata":{"id":"b3sTcuvAHxU4"}},{"cell_type":"code","source":["None"],"metadata":{"id":"eZ9Z5ZyjHxJc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez le modèle avec la méthode `forward`."],"metadata":{"id":"W4cZNohmIK_m"}},{"cell_type":"code","source":["test = torch.randn(1, 1, 128)\n","result = None\n","result.shape"],"metadata":{"id":"JQnLD7aN2bZJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialisez `criterion` avec la fonction `L1Loss`.\n","\n","Initialisez `optimizer` avec `Adam` et un learning rate de 0.001."],"metadata":{"id":"ErnhzBgQ4Jsy"}},{"cell_type":"code","source":["criterion = None\n","optimizer = None"],"metadata":{"id":"TKH7ks7x39I4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch = 3000"],"metadata":{"id":"zEtSvS9S4vkb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la fonction `fit` pour entraîner le modèle."],"metadata":{"id":"0Fh2Xm8cIc5K"}},{"cell_type":"code","source":["model, history_train_loss, history_test_loss = None"],"metadata":{"id":"dfdADOP74z5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la méthode `forward` pour prédire le résultat du modèle à partir de `signal_noise_expand`"],"metadata":{"id":"UIQnZlV-ekmx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3isbDOv6wTq"},"outputs":[],"source":["signal_pred = None"]},{"cell_type":"markdown","source":["Utilisez la fonction `write` du package `soundfile` pour enregistrer `signal_noise_expand`, `signal_exapnd` et `signal_pred` avec pour nom respectif `reel_1.wav`, `pred_1.wav` et `noise_1.wav`."],"metadata":{"id":"V7O-gH2SeuoN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-sVC2di6hKR"},"outputs":[],"source":["sf.write(None)\n","sf.write(None)\n","sf.write(None)"]},{"cell_type":"markdown","source":["Ecoutez le résultat afin de voir s'il est satisfaiant."],"metadata":{"id":"Z7qfo6B4fCob"}},{"cell_type":"markdown","source":["## Modèle finale"],"metadata":{"id":"QWapJh3pgPAa"}},{"cell_type":"markdown","source":["Maintenant que vous avez construit votre baseline L'objectif de ce TP est de complexifier le modèle jusqu'à ce qu'il soit capable de débruiter parfaitement le son bruité."],"metadata":{"id":"SE2qYk6lIt1i"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":0}