{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"13EAg69bXVyMFK1-dzXWBsigo9quIXpOY","timestamp":1730561443968}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Oh8EYBrfVLRK"},"source":["# Diagnostiquez automatiquement des radios thoraciques."]},{"cell_type":"markdown","metadata":{"id":"QeMWml9mVexn"},"source":["Maintenant que vous avez découvert les CNN et que vous savez entraîner des modèles avec Pytorch, vous allez pouvoir utiliser vos nouvelles connaissances pour résoudre un problème plus concret.\n","\n","Dans ce notebook, vous allez entraîner un algorithme capable de diagnostiquer automatiquement si notre patient est atteint d'une pneumonie ou non grâce à sa radiographie thoracique. Les données viennent de ce [datasets](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) de Kaggle.\n"]},{"cell_type":"markdown","metadata":{"id":"9-djk5ueapTa"},"source":["# Importation des packages"]},{"cell_type":"code","metadata":{"id":"9e6Go76WaraU"},"source":["import matplotlib.pyplot as plt\n","\n","import os\n","import numpy as np\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","import torch as torch\n","from torchvision import datasets, transforms\n","from torchsummary import summary\n","from collections import OrderedDict\n","\n","from torch.utils.data import Subset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QpsYO6ibasNi"},"source":["# Importation des données"]},{"cell_type":"markdown","metadata":{"id":"fKwIB4gnayv4"},"source":["Ajoutez un raccourci de ce dossier à votre google drive :\n","\n","https://drive.google.com/drive/folders/1F1MiX9qQ7ZoafVq68x6ISWgtOsZf7CCi?usp=sharing"]},{"cell_type":"code","metadata":{"id":"UucK2DRWauNc"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BPnbRzHthHW-"},"source":["Visualisons nos données !"]},{"cell_type":"code","metadata":{"id":"tvLZJbVohHmN"},"source":["\n","input_path = '/content/drive/MyDrive/chest_xray/'\n","\n","fig, ax = plt.subplots(2, 3, figsize=(15, 7))\n","ax = ax.ravel()\n","plt.tight_layout()\n","\n","for i, _set in enumerate(['train', 'val', 'test']):\n","    set_path = input_path+_set\n","    ax[i].imshow(plt.imread(set_path+'/NORMAL/'+os.listdir(set_path+'/NORMAL') [i]), cmap='gray')\n","    ax[i].set_title('Set: {}, Condition: Normal'.format(_set))\n","    ax[i+3].imshow(plt.imread(set_path+'/PNEUMONIA/'+os.listdir(set_path+'/PNEUMONIA') [i]), cmap='gray')\n","    ax[i+3].set_title('Set: {}, Condition: Pneumonia'.format(_set))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRPT5W-njKtL"},"source":["normal_example = os.listdir(f'{input_path}train/NORMAL')[3]\n","pneumonia_example = os.listdir(f'{input_path}train/PNEUMONIA')[3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vWEsZ85jMwS"},"source":["normal_img = plt.imread(f'{input_path}train/NORMAL/{normal_example}')\n","plt.imshow(normal_img)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swOmNcQDjRBe"},"source":["pneumonia_img = plt.imread(f'{input_path}train/PNEUMONIA/{pneumonia_example}')\n","plt.imshow(pneumonia_img)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sC8uxDl-0d89"},"source":["test_labels = []\n","for cond in ['/NORMAL/', '/PNEUMONIA/']:\n","        for img in (os.listdir(input_path + 'test' + cond)):\n","          if cond=='/NORMAL/':\n","              label = 0\n","          elif cond=='/PNEUMONIA/':\n","              label = 1\n","          test_labels.append(label)\n","\n","test_labels = np.array(test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JexKLxmvjt1w"},"source":["# Initialiser les générateurs"]},{"cell_type":"markdown","metadata":{"id":"GTKqNVXGkMSC"},"source":["Utilisez la classe *transforms* pour appliquer des transformation à vos images. C'est cette classe qui est aussi utilisez pour effectuer de la data augmentation.\n","\n","Appliquez :\n","- `Resize` en 255x255 pour réduire le nombre de paramètres,\n","- `Grayscale`,\n","- `ToTensor` pour transformer l'image en tenseur.\n","\n","N'hésitez pas à chercher de l'aide dans la [documentation](https://pytorch.org/vision/0.9/transforms.html)."]},{"cell_type":"code","source":["transform = None"],"metadata":{"id":"mFn90I_mtkwM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la fonction `ImageFolder` en utilisant le path ou se trouve les données '/content/drive/MyDrive/chest_xray/train_small' et la fonction `transform`.\n","\n","N'hésitez pas à regarder la [documentation](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)."],"metadata":{"id":"KWSC5uHiwhVK"}},{"cell_type":"code","source":["dataset_train = None"],"metadata":{"id":"_CxT-os8whJK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qW7q1Ds0lCqd"},"source":["Vous n'allez pas charger directement toutes les images en mémoire pendant l'entraînement. Vous allez utilisez la fonction *flow_from_directory* pour renseigner l'endroit ou se trouve vos images. Les images seront lu batch par batch.\n","\n","Utilisez :\n","- `dataset` ,\n","- un batch de 32 ,\n","- un shuffle à True.\n","\n","N'hésitez pas à regarder la [documentation](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)."]},{"cell_type":"code","source":["dataloader_train = None"],"metadata":{"id":"wAJaxkPWwKmw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualisation du générateur."],"metadata":{"id":"uC7llDqzxSy_"}},{"cell_type":"code","source":["for x, y in dataloader_train:\n","  print(x[0].shape)\n","  print(y[0])\n","  plt.imshow(x[0].permute(1, 2, 0))\n","  break"],"metadata":{"id":"bMIU9faEwLzU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D2fSV_T9nX4M"},"source":["Faire de même pour le jeu de test et de validation."]},{"cell_type":"code","metadata":{"id":"A2TFqQmrniZO"},"source":["dataset_test = None\n","\n","dataloader_test = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dqFKtCZRmij8"},"source":["# Initialisez votre modèle"]},{"cell_type":"markdown","source":["Créez l'architecture suivante:\n","- Convolution avec 16 filtres de 3 de côté,\n","- Relu,\n","- Maxpooling avec 2 de côté et un stride de 2,\n","- Convolution avec 32 filtres de 3 de côté,\n","- Relu,\n","- Maxpooling avec 2 de côté et un stride de 2,\n","- Convolution avec 64 filtres de 3 de côté,\n","- Relu,\n","- Maxpooling avec 2 de côté et un stride de 2,\n","- Convolution avec 128 filtres de 3 de côté,\n","- Relu,\n","- Maxpooling avec 2 de côté et un stride de 2,\n","- Flatten,\n","- Linear avec 4608 données en entrée et 64 neurones,\n","- Relu,\n","- Linear avec 10 neurones,\n","- Softmax."],"metadata":{"id":"a1vZtR6lTMZI"}},{"cell_type":"code","metadata":{"id":"Adk0qJbMmkqI"},"source":["model = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Affiche l'architecture avec `print`"],"metadata":{"id":"ZBpxPV4GT0JO"}},{"cell_type":"code","source":["None"],"metadata":{"id":"phdL9zGeT4ec"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Affiche le modèle en utilisant `summary`."],"metadata":{"id":"gtxDn4Z1T3HY"}},{"cell_type":"code","metadata":{"id":"Ikvt2rh3pz4o"},"source":["None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Les fonctions d'entraînement"],"metadata":{"id":"UnZdXXikyDLz"}},{"cell_type":"markdown","source":["Utilisez la fonction `save` pour sauver le modèle passé en paramètre au chemin indiqué en paramètre."],"metadata":{"id":"JFdZcYnsUHjZ"}},{"cell_type":"code","source":["def save_model(model, path):\n","    None"],"metadata":{"id":"TS3UX59605we"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def number_of_good_prediction(prediction:float, target:int):\n","  one_hot_prediction = np.argmax(prediction, axis=1)\n","  return np.sum(one_hot_prediction == target)"],"metadata":{"id":"Gail3mawyHcv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def step(model:torch.nn.Sequential,\n","         opt:torch.optim,\n","         criterion:torch.nn.modules.loss,\n","         x_train:torch.Tensor,\n","         y_train:torch.Tensor,\n","         metric_function)->tuple:\n","  \"\"\"\n","  Executes a single training step for a PyTorch model.\n","  This function performs a forward pass to compute the model's predictions, calculates\n","  the loss between predictions and actual target values, computes gradients for each\n","  model parameter, and updates the parameters using the optimizer.\n","\n","  Args:\n","      model (torch.nn.Sequential): The PyTorch model to train.\n","      optimizer (torch.optim.Optimizer): Optimizer used to update the model's parameters.\n","      criterion (torch.nn.modules.loss._Loss): Loss function used to compute the error.\n","      x_train (torch.Tensor): Input training data (features).\n","      y_train (torch.Tensor): Ground truth labels or target values for the training data.\n","  Returns:\n","      tuple: The updated model and the computed loss for the current step.\n","  \"\"\"\n","\n","  # Réinitialisez les gradients d'optimizer à zéro avec la méthode 'zero_grad'\n","  opt.zero_grad()\n","\n","  # Calculez les prédiction sur le jeu d'entraînement avec la méthode 'froward'\n","  prediction = model.forward(x_train)\n","\n","  # Calculez l'erreur de prédiction avec 'criterion'\n","  loss = criterion(prediction, y_train)\n","\n","  performance = metric_function(prediction.detach().numpy(), y_train.detach().numpy())\n","\n","  # Calculez les gradients avec la méthode 'backward'\n","  loss.backward()\n","\n","  # Mettre à jour les paramètres du modèle avec la méthode 'step'\n","  opt.step()\n","\n","  return model, loss, performance"],"metadata":{"id":"WlIfHeQmyHvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fit(model, optimizer, criterion, epoch, trainloader, testloader, metric_function):\n","    epoch = epoch\n","    history_train_loss = []\n","    history_test_loss = []\n","    history_train_metrics = []\n","    history_test_metrics = []\n","\n","    reference_performance = 0\n","\n","    for e in range(epoch) :\n","\n","      train_loss_batch = 0\n","      test_loss_batch = 0\n","      train_metric_batch = 0\n","      test_metric_batch = 0\n","\n","      for images, labels in trainloader:\n","\n","        # mise à jour des poids avec la fonction 'step'\n","        model, train_loss, train_performance = step(model, optimizer, criterion, images, labels, metric_function)\n","\n","        train_loss_batch += train_loss.detach().numpy()\n","\n","        train_metric_batch += train_performance\n","\n","\n","      for images, labels in testloader:\n","\n","        prediction = model.forward(images)\n","\n","        test_loss = criterion(prediction, labels)\n","\n","        test_metric_batch += metric_function(prediction.detach().numpy(), labels.detach().numpy())\n","\n","        test_loss_batch += test_loss.detach().numpy()\n","\n","      train_loss_batch /= len(trainloader.sampler)\n","      test_loss_batch /= len(testloader.sampler)\n","\n","      train_metric_batch /= len(trainloader.sampler)\n","      test_metric_batch /= len(testloader.sampler)\n","\n","      # Sauvegarde des coûts d'entraînement avec append\n","      history_train_loss = np.append(history_train_loss, train_loss_batch)\n","      history_test_loss = np.append(history_test_loss, test_loss_batch)\n","\n","      # Sauvegarde des coûts d'entraînement avec append\n","      history_train_metrics = np.append(history_train_metrics, train_metric_batch)\n","      history_test_metrics = np.append(history_test_metrics, test_metric_batch)\n","\n","      print('train_loss : '+str(np.squeeze(train_loss_batch))+ ' test_loss : '+str(np.squeeze(test_loss_batch)))\n","      print('train_metric : '+str(np.squeeze(train_metric_batch))+ ' test_metric : '+str(np.squeeze(test_metric_batch)))\n","      print('-------------------------------------------------------------------------------------------------')\n","\n","      if test_metric_batch > reference_performance:\n","        reference_performance = test_metric_batch\n","        save_model(model, f'best_model_{test_metric_batch}.pth')\n","\n","    return model, history_train_loss, history_test_loss, history_train_metrics, history_test_metrics\n"],"metadata":{"id":"kWe6DLlOyJlI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialisez `criterion` avec la fonction `NLLLoss`.\n","\n","Initialisez `optimizer` avec `Adam` et un learning rate de 0.001."],"metadata":{"id":"1kYdiDTh0nDc"}},{"cell_type":"code","metadata":{"id":"yvUOiQ4Jm1-2"},"source":["criterion = None\n","optimizer = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_XNG1YZOm6sz"},"source":["# Entraînez votre modèle"]},{"cell_type":"code","source":["epoch = 10"],"metadata":{"id":"BIH-knUT14Zb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la fonction `fit` pour entraîner le modèle."],"metadata":{"id":"i2B9tyyeUDn1"}},{"cell_type":"code","metadata":{"id":"k67z1yUFnLYJ"},"source":["model, history_train_loss, history_test_loss, history_train_metrics, history_test = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1JkjDrBeoC36"},"source":["# Visualisation des performances"]},{"cell_type":"code","metadata":{"id":"aXXUbvB3oChf"},"source":["plt.plot(np.arange(epoch), history_train_loss, label='train loss')\n","plt.plot(np.arange(epoch), history_test_loss, label='test loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('loss')\n","plt.legend(loc='upper left')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history_train_metrics, label='train accuracy')\n","plt.plot(history_test, label='test accuracy')\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(loc='upper left')\n","plt.show()"],"metadata":{"id":"3GVBJLe82TSG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rGNIa15I77j5"},"execution_count":null,"outputs":[]}]}