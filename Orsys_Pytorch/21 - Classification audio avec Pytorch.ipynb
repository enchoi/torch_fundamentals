{"cells":[{"cell_type":"markdown","metadata":{"id":"pyyufcYvd84S"},"source":["# Prétraitement des données audio"]},{"cell_type":"markdown","metadata":{"id":"mNjCaJY7gC1Z"},"source":["# Importation des packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v71WgwXDd5v3"},"outputs":[],"source":["import librosa, librosa.display\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import json\n","from sklearn.model_selection import train_test_split\n","import torch as torch\n","from torch.utils.data import Dataset\n","from torchsummary import summary"]},{"cell_type":"markdown","metadata":{"id":"rPsDRfOLiJQ0"},"source":["# Connection avec Google Drive"]},{"cell_type":"markdown","metadata":{"id":"0gyxdRT-iSbz"},"source":["Ajoutez un raccourci de ce dossier à votre google drive :\n","\n","https://drive.google.com/drive/folders/1NGH6ntk3qH8Odo7q8YxDS0iqV-httZUR?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnrxxvGsiSAv"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XPfxOjwjieEJ"},"outputs":[],"source":["file = \"drive/MyDrive/Music_genre_classification/genres_original/pop/pop.00008.wav\""]},{"cell_type":"markdown","source":["Utilisez la fonction `load` de `librosa` pour charger le son."],"metadata":{"id":"DfPilJvAc1JT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lm8Wqk1ai6F4"},"outputs":[],"source":["signal, sr = None"]},{"cell_type":"markdown","source":["Utilisez la fonction `waveshow` de `librosa` pour afficher le son."],"metadata":{"id":"eNM3xdB1c9HM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E60MC3UIi8hM"},"outputs":[],"source":["None\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"Amplitude\")\n","plt.show()"]},{"cell_type":"markdown","source":["Utilisez la fonction `fft` de `numpy` pour calculer la fast fourier transform."],"metadata":{"id":"VhRGOFKVdDvu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gIOv6rkDjaXJ"},"outputs":[],"source":["fft = None"]},{"cell_type":"markdown","source":["Utilisez la fonction `abs` de `numpy` pour obtenir la valeur absolu de `fft` et ainsi obtenir la magnitude de l'onde."],"metadata":{"id":"Fz8Jo9QidJ0O"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPvvG-MjkXMa"},"outputs":[],"source":["magnitude = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9hzJj2YkhVV"},"outputs":[],"source":["frequency = np.linspace(0, sr, len(magnitude))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNiOfNkXktPY"},"outputs":[],"source":["plt.plot(frequency, magnitude)\n","plt.xlabel(\"Frequency\")\n","plt.ylabel(\"Magnitude\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzXISNAukyYN"},"outputs":[],"source":["left_frequency = frequency[:int(len(frequency)/2)]\n","left_magnitude = magnitude[:int(len(frequency)/2)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"anyltC32lUiY"},"outputs":[],"source":["plt.plot(left_frequency, left_magnitude)\n","plt.xlabel(\"Frequency\")\n","plt.ylabel(\"Magnitude\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oh1gCtWvljvr"},"outputs":[],"source":["n_fft=2048 # Number of time for each sample\n","hop_length = 512 # the amount we slide to the right"]},{"cell_type":"markdown","source":["Utilisez la fonction `stft` pour appliquer la Short-time Fourier transform sur le `signal`, utilisez la hyperparamètre `n_fft` et `hop_length` proposé."],"metadata":{"id":"1_kJdoxqdZPI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxZdlAQxlbDN"},"outputs":[],"source":["stft = None"]},{"cell_type":"markdown","source":["Appliquez la fonction `abs` de `numpy` pour obtenir le spectogram."],"metadata":{"id":"rmkYz6yNdqhv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZ35cuPjl6K5"},"outputs":[],"source":["spectogram = None"]},{"cell_type":"markdown","source":["Utilisez la fonction `specshow` de `librosa` pour afficher le spectogram."],"metadata":{"id":"WPbcxJlzdwYG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"duO1rS4Xl-vG"},"outputs":[],"source":["None\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"Frequency\")\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","source":["Ce n'est pas très facile à interpréter.\n","\n","Utilisez la fonction `amplitude_to_db` pour appliquer le logatirhme à `spectogram` et obtenir le résultat en db."],"metadata":{"id":"IGATIY67d1gN"}},{"cell_type":"code","source":["log_spectogram = None"],"metadata":{"id":"VvrVUwZ2d_vs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez à nouveau la fonction `specshow` pour afficher le résultat obtenu."],"metadata":{"id":"dm7yLd92eBrX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8sU9ll5NmBww"},"outputs":[],"source":["None\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"Frequency\")\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","source":["Utilisez la fonction `mfcc` de `librosa` pour appliquer le Mel-frequency cepstral coefficients de l'onde.\n","\n","Prenez un `n_mfcc` de 13."],"metadata":{"id":"K0BWm8zdeGIF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6iiJdZvvmhaP"},"outputs":[],"source":["MFFCs = None"]},{"cell_type":"markdown","source":["Utilisez la fonction `specshow` pour visualiser le résultat de la fonction `mfcc`."],"metadata":{"id":"_lZaXBr6eXQp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DyAs8jBgm8CG"},"outputs":[],"source":["None\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"MFCC\")\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"l-DIcITjL5O8"},"source":["# Création du jeu de données"]},{"cell_type":"markdown","metadata":{"id":"X_o780n6MPlE"},"source":["Regardez le nombre total de genre à classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JkQMFRW1NN_3"},"outputs":[],"source":["for i, (dirpath, dirnames, filesnames) in enumerate(os.walk(\"drive/MyDrive/Music_genre_classification/genres_original/\")):\n","\n","  # ensure that we're not at the root level\n","  if dirpath != \"drive/MyDrive/Music_genre_classification/genres_original/\":\n","    dirpath_components = dirpath.split(\"/\")\n","    semantic_label = dirpath_components[-1]\n","    print(semantic_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnNKikZ5P6U9"},"outputs":[],"source":["# sample rate\n","SAMPLE_RATE = 22050\n","\n","# Longueur de chaque morceau du jeu de données\n","DURATION = 30\n","\n","# durée de chaque segment de chanson\n","SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION"]},{"cell_type":"markdown","source":["La fonction suivante va diviser chaque son en segment 5 segments et calculer le mfcc sur chacun de ces segments.\n","\n","Ces résultats seront stocker dans un dictionnaire qui sera sauvegarder en json.\n","\n","Cette opération peut prendre du temps, donc je vous laisse à disposition le résultat final de cette opération."],"metadata":{"id":"4gTXtukbe0rV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PL0POIxVncFy"},"outputs":[],"source":["def save_mfcc(dataset_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n","  \"\"\"\n","\n","  \"\"\"\n","  # dictionary to store data\n","  data = {\n","      \"mapping\": [],\n","      \"labels\": [],\n","      \"mfcc\": []\n","  }\n","\n","  num_samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n","  expected_num_mfcc_vectors_per_segment = np.ceil(num_samples_per_segment / hop_length)\n","\n","  # Loop through all the genres\n","\n","  for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n","\n","    # ensure that we're not at the root level\n","    if dirpath is not dataset_path:\n","\n","      # save the semantic label\n","      dirpath_components = dirpath.split(\"/\")\n","      semantic_label = dirpath_components[-1]\n","      data[\"mapping\"].append(semantic_label)\n","      print('\\nProcessing {}'.format(semantic_label))\n","\n","      # process files for a specific genre\n","      for f in filenames:\n","        # load the audio file\n","        file_path = os.path.join(dirpath, f)\n","        signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n","\n","        # process segments extracting mfcc and sotring data\n","        for s in range(num_segments):\n","          start_sample = num_samples_per_segment * s\n","          finish_sample = start_sample + num_samples_per_segment\n","\n","          mfcc = librosa.feature.mfcc(y=signal[start_sample:finish_sample],\n","                                      sr=sr,\n","                                      n_fft=n_fft,\n","                                      n_mfcc=n_mfcc,\n","                                      hop_length=hop_length)\n","\n","          mfcc = mfcc.T\n","\n","          # store mfcc for segment if it has the expected length\n","          if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n","            data[\"mfcc\"].append(mfcc.tolist())\n","            data[\"labels\"].append(i-1)\n","            print(\"{}, segment:{}\".format(file_path, s))\n","\n","  with open(json_path, \"w\") as fp:\n","    json.dump(data, fp, indent=4)\n"]},{"cell_type":"markdown","source":["Calcul, création et sauvegarde du jeu de données."],"metadata":{"id":"U69WL4iafU7E"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kWm87PJOhHX"},"outputs":[],"source":["#data = save_mfcc(dataset_path=\"drive/MyDrive/Music_genre_classification/genres_original/\",\n","#          json_path=\"drive/MyDrive/Music_genre_classification/genres_original/data.json\",\n","#          num_segments=10)"]},{"cell_type":"markdown","source":["Chargement des données"],"metadata":{"id":"VJFwI58LfSjA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_uZwypEksIT"},"outputs":[],"source":["def load_data(dataset_path):\n","  with open(dataset_path, \"r\") as fp:\n","    data = json.load(fp)\n","\n","    # Convert lists into numpy arrays\n","    inputs = np.array(data[\"mfcc\"])\n","    targets = np.array(data[\"labels\"])\n","\n","    return inputs, targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nbwfa2X0KdSB"},"outputs":[],"source":["inputs, targets = load_data(\"drive/MyDrive/Music_genre_classification/genres_original/data.json\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uYKLyYvKuH4"},"outputs":[],"source":["inputs.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SA1aPfE_KvSs"},"outputs":[],"source":["targets.shape"]},{"cell_type":"markdown","source":["Utilisez la fonction `train_test_split` pour séparer le jeu de données en jeu de d'entraînement et de test à partir de `inputs` et `targets`."],"metadata":{"id":"_BeCqgnGfd13"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KNh7W_L4K9Xr"},"outputs":[],"source":["inputs_train, inputs_test, targets_train, targets_test = None"]},{"cell_type":"markdown","metadata":{"id":"5B2cyL7wLkK8"},"source":["# Deep learning classique"]},{"cell_type":"markdown","metadata":{"id":"GqGiZr0Is0PN"},"source":["# Créer le générateur"]},{"cell_type":"markdown","source":["Création d'un générateur adapté à notre application."],"metadata":{"id":"WdZKzbXjfsTF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QqUVYJLIvRL"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, x_train, y_train):\n","        self.input = x_train\n","        self.output = y_train\n","\n","    def __len__(self):\n","        return len(self.output)\n","\n","    def __getitem__(self, idx):\n","        batch_input = self.input[idx, :, :]\n","        batch_output = self.output[idx]\n","\n","        return batch_input, batch_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwW4mBmWKqqi"},"outputs":[],"source":["x_training = CustomDataset(torch.from_numpy(np.float32(inputs_train)),\n","                                 torch.from_numpy(targets_train))"]},{"cell_type":"markdown","source":["Utilisez la fonction `DataLoader` pour créer le générateur avec une taille de batch de 32."],"metadata":{"id":"Zuuh4ISGfwQc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjj0-LgVK5fw"},"outputs":[],"source":["dataloader_train = None"]},{"cell_type":"markdown","source":["Vérification que le générateur fonction bien."],"metadata":{"id":"UQF-NckFf3Xp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7YsuiZRDKztc"},"outputs":[],"source":["for x, y in dataloader_train:\n","  print(x.shape)\n","  print(y.shape)\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPIrFkyeLATt"},"outputs":[],"source":["x_testing = CustomDataset(torch.from_numpy(np.float32(inputs_test)),\n","                                 torch.from_numpy(targets_test))"]},{"cell_type":"markdown","source":["Utilisez la fonction `DataLoader` pour créer le générateur de test."],"metadata":{"id":"1-rQl_Pzf5sE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"m04iSFWYLA5t"},"outputs":[],"source":["dataloader_test = None"]},{"cell_type":"markdown","source":["Vérification du générateur de test"],"metadata":{"id":"D4ihK71mf_0w"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vqozA_oeLBkZ"},"outputs":[],"source":["for x, y in dataloader_test:\n","  print(x.shape)\n","  print(y.shape)\n","  break"]},{"cell_type":"markdown","metadata":{"id":"4HMaBN90LO26"},"source":["# Entraînement du modèle"]},{"cell_type":"markdown","metadata":{"id":"kEAOf42iLVss"},"source":["## Fonction d'entraînement"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lj_4SXYfgBwn"},"outputs":[],"source":["def number_of_good_prediction(prediction:float, target:int):\n","  one_hot_prediction = np.argmax(prediction, axis=1)\n","  return np.sum(one_hot_prediction == target)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6TwXnQWpLXVn"},"outputs":[],"source":["def step(model:torch.nn.Sequential,\n","         opt:torch.optim,\n","         criterion:torch.nn.modules.loss,\n","         x_train:torch.Tensor,\n","         y_train:torch.Tensor,\n","         metric_function)->tuple:\n","  \"\"\"\n","  Executes a single training step for a PyTorch model.\n","  This function performs a forward pass to compute the model's predictions, calculates\n","  the loss between predictions and actual target values, computes gradients for each\n","  model parameter, and updates the parameters using the optimizer.\n","\n","  Args:\n","      model (torch.nn.Sequential): The PyTorch model to train.\n","      optimizer (torch.optim.Optimizer): Optimizer used to update the model's parameters.\n","      criterion (torch.nn.modules.loss._Loss): Loss function used to compute the error.\n","      x_train (torch.Tensor): Input training data (features).\n","      y_train (torch.Tensor): Ground truth labels or target values for the training data.\n","  Returns:\n","      tuple: The updated model and the computed loss for the current step.\n","  \"\"\"\n","\n","  # Réinitialisez les gradients d'optimizer à zéro avec la méthode 'zero_grad'\n","  opt.zero_grad()\n","\n","  # Calculez les prédiction sur le jeu d'entraînement avec la méthode 'froward'\n","  prediction = model.forward(x_train)\n","\n","  # Calculez l'erreur de prédiction avec 'criterion'\n","  loss = criterion(prediction, y_train)\n","\n","  performance = metric_function(prediction.detach().numpy(), y_train.detach().numpy())\n","\n","  # Calculez les gradients avec la méthode 'backward'\n","  loss.backward()\n","\n","  # Mettre à jour les paramètres du modèle avec la méthode 'step'\n","  opt.step()\n","\n","  return model, loss, performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ynIGwtbwLZED"},"outputs":[],"source":["def fit(model, optimizer, criterion, epoch, trainloader, testloader, metric_function):\n","    epoch = epoch\n","    history_train_loss = []\n","    history_test_loss = []\n","    history_train_metrics = []\n","    history_test_metrics = []\n","\n","    for e in range(epoch) :\n","\n","      train_loss_batch = 0\n","      test_loss_batch = 0\n","      train_metric_batch = 0\n","      test_metric_batch = 0\n","\n","      for images, labels in trainloader:\n","\n","        # mise à jour des poids avec la fonction 'step'\n","        model, train_loss, train_performance = step(model, optimizer, criterion, images, labels, metric_function)\n","\n","        train_loss_batch += train_loss.detach().numpy()\n","\n","        train_metric_batch += train_performance\n","\n","      for images, labels in testloader:\n","\n","        prediction = model.forward(images)\n","\n","        test_loss = criterion(prediction, labels)\n","\n","        test_metric_batch += metric_function(prediction.detach().numpy(), labels.detach().numpy())\n","\n","        test_loss_batch += test_loss.detach().numpy()\n","\n","      train_loss_batch /= len(trainloader.sampler)\n","      test_loss_batch /= len(testloader.sampler)\n","\n","      train_metric_batch /= len(trainloader.sampler)\n","      test_metric_batch /= len(testloader.sampler)\n","\n","      # Sauvegarde des coûts d'entraînement avec append\n","      history_train_loss = np.append(history_train_loss, train_loss_batch)\n","      history_test_loss = np.append(history_test_loss, test_loss_batch)\n","\n","      # Sauvegarde des coûts d'entraînement avec append\n","      history_train_metrics = np.append(history_train_metrics, train_metric_batch)\n","      history_test_metrics = np.append(history_test_metrics, test_metric_batch)\n","\n","      print(f'epoch : {e}/{epoch}')\n","      print('train_loss : '+str(np.squeeze(train_loss_batch))+ ' test_loss : '+str(np.squeeze(test_loss_batch)))\n","      print('train_metric : '+str(np.squeeze(train_metric_batch))+ ' test_metric : '+str(np.squeeze(test_metric_batch)))\n","      print('-------------------------------------------------------------------------------------------------')\n","\n","    return model, history_train_loss, history_test_loss, history_train_metrics, history_test_metrics\n"]},{"cell_type":"markdown","metadata":{"id":"iCU3aYguLSYK"},"source":["## Création de l'architecture"]},{"cell_type":"markdown","source":["Utilisez la fonction `Sequantial` pour intialiser l'architecture suivante:\n","- Apppliquer une couche de flatten pour transformer la matrice d'entrée en vecteur.\n","- Créez une couche dense de 512 neurones avec la fonction `Linear`,\n","- Appliquer Relu en fonction d'acitvation,\n","- Créer une couche dense avec 256 neurones,\n","- Appliquer le Relu,\n","- Créer une couche de 10 neurones,\n","- Appliquer la fonction LogSoftmax.\n"],"metadata":{"id":"6Z0hCE7wgFrb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"70vAZlhZtmQq"},"outputs":[],"source":["model_deep = None"]},{"cell_type":"markdown","source":["Utilisez la fonction `summary` pour visualiser le modèle.\n","\n","Attention si vous êtes dans une session avec gpu utilisez en paramètre `device='cpu'`"],"metadata":{"id":"AaxuCJkcgp5F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"E5nwUOcYMPYz"},"outputs":[],"source":["None"]},{"cell_type":"markdown","source":["Utilisez la fonction `NLLLoss` pour fonction de coût.\n","\n","Utilisez la fonction `Adam` comme optimizer avec un learning rate de 0.001."],"metadata":{"id":"7o7GFujcg7NY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ognYlBvtqA2"},"outputs":[],"source":["criterion = None\n","optimizer = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oip1io-cMmXF"},"outputs":[],"source":["epoch = 10"]},{"cell_type":"markdown","source":["Utilisez la fonction `fit` pour entraîner le modèle."],"metadata":{"id":"TFPkmYW2hEdS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4A3N4n5MMogk"},"outputs":[],"source":["model, history_train_loss_deep, history_test_loss_deep, history_train_metrics_deep, history_test_metrics_deep = None"]},{"cell_type":"markdown","metadata":{"id":"RMxwoxkBxeOS"},"source":["# CNN"]},{"cell_type":"markdown","source":["On va devoir changer l'opérateur car on doit ajouter un channel pour le CNN."],"metadata":{"id":"Kob8E4TDhQg3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3SC8wWhNeX9"},"outputs":[],"source":["x_training = CustomDataset(torch.from_numpy(np.float32(np.expand_dims(inputs_train, axis=1))),\n","                                 torch.from_numpy(targets_train))"]},{"cell_type":"markdown","source":["UTilisez la fonction `DataLoader` pour créer le générateur d'entraînement."],"metadata":{"id":"InScktW8hKBU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArGwCSVFNeX9"},"outputs":[],"source":["dataloader_train_cnn = None"]},{"cell_type":"markdown","source":["Vérification du générateur d'entraînement."],"metadata":{"id":"o9dtlJ9xhVGs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"euB-OEOKNeX9"},"outputs":[],"source":["for x, y in dataloader_train_cnn:\n","  print(x.shape)\n","  print(y.shape)\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbQFOXr-NeX9"},"outputs":[],"source":["x_testing = CustomDataset(torch.from_numpy(np.float32(np.expand_dims(inputs_test, axis=1))),\n","                                 torch.from_numpy(targets_test))"]},{"cell_type":"markdown","source":["Utilisez la fonction `Data Loader` pour initialiser le générateur de test."],"metadata":{"id":"LYpsEty2hXMc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtq2lOl7NeX-"},"outputs":[],"source":["dataloader_test_cnn = None"]},{"cell_type":"markdown","source":["Vérification du générateur de test."],"metadata":{"id":"w995xmCahmzn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_virDtwNeX-"},"outputs":[],"source":["for x, y in dataloader_test_cnn:\n","  print(x.shape)\n","  print(y.shape)\n","  break"]},{"cell_type":"markdown","source":["## Initialisation de l'architecture\n","\n","\n","Utilisez la fonction `Sequantial` pour initialiser l'architecture suivante:\n","- Une couche de convolution avec 32 filtres,\n","- Une couche d'activation Relu,\n","- Une couche de maxpooling,\n","- Une couche de convolution avec 64 filtres,\n","- Une couche d'activation Relu,\n","- Une couche de maxpooling,\n","- Une couche de Flatten,\n","- Une couche Linéaire avec 64 neurones,\n","- Une couche de Relu,\n","- Une couche linéaire avec 10 neurones,\n","- Une couche d'activation Logsoftmax"],"metadata":{"id":"2ozUMHj4hoYa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrVbVR73N7f0"},"outputs":[],"source":["model_cnn = None"]},{"cell_type":"markdown","source":["Utilisez la fonction `summary`pour visualiser le modèle."],"metadata":{"id":"z9ZVuBIkiKqU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftS5IDEeOZzc"},"outputs":[],"source":["None"]},{"cell_type":"markdown","source":["Utilisez la fonction `NLLLoss` pour fonction de coût.\n","\n","Utilisez la fonction `Adam` comme optimizer avec un learning rate de 0.001."],"metadata":{"id":"Ezr4bDHqiQDG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4_s1iJUz7gp"},"outputs":[],"source":["criterion = None\n","optimizer = None"]},{"cell_type":"markdown","source":["Utilisez la fonction `fit` pour entraîner le modèle."],"metadata":{"id":"WxDq7VpYiW4D"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXKT0751gsU2"},"outputs":[],"source":["model, history_train_loss_cnn, history_test_loss_cnn, history_train_metrics_cnn, history_test_metrics_cnn = None"]},{"cell_type":"markdown","metadata":{"id":"lQ-T8HUn1GMT"},"source":["# RNN"]},{"cell_type":"markdown","source":["Définir le modèle de la manière suivante.\n","\n","Dans `__init__` vous allez créer des attributs à la classe reprenant les opérations que vous allez vouloir utiliser dans le modèle.\n","\n","Dans `foward` vous allez appliquer le graph de calcul que vous voulez utiliser.\n","\n","L'architecture est la suivante:\n","- Une couche de RNN,\n","- Une couche de linéaire qui prend en entrée la dernière couche caché de la séquence et avec 64 neurones,\n","- Une couche d'activation Relu,\n","- Une couche linéiare avec 10 neurones,\n","- Une couche d'activation logsoftmax,"],"metadata":{"id":"MmjgXzMpicx5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7vab2ZfVPcdo"},"outputs":[],"source":["# Définir le modèle RNN\n","class RNNModel(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(RNNModel, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        # Couche RNN\n","        self.rnn = None\n","\n","        # Couche après le RNN\n","        self.fc1 = None\n","\n","        # Couche entièrement connectée pour la sortie\n","        self.fc2 = None\n","\n","        self.softmax = None\n","\n","    def forward(self, x):\n","        # Initialiser l'état caché avec des zéros\n","        h0 = None\n","\n","        # Passer les données dans la couche RNN\n","        out, h_n = None\n","\n","        fc1 = None\n","\n","        fc2 = None\n","\n","        proba = None\n","        return proba"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZfpOcBXoPfBK"},"outputs":[],"source":["# Définir les dimensions d'entrée et de sortie\n","input_size = 13\n","hidden_size = 128\n","num_layers = 1\n","output_size = 10\n","\n","# Initialiser le modèle\n","model_rnn = RNNModel(input_size, hidden_size, num_layers, output_size)"]},{"cell_type":"markdown","source":["Utilisez la fonction `summary` pour visualiser le modèle."],"metadata":{"id":"BOHXTwVgjVxb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkZf3BllPmJL"},"outputs":[],"source":["None"]},{"cell_type":"markdown","source":["Utilisez la fonction `NLLLoss` pour fonction de coût.\n","\n","Utilisez la fonction `Adam` comme optimizer avec un learning rate de 0.001."],"metadata":{"id":"_ziBsE1kiSjR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wg6P26_OPs7i"},"outputs":[],"source":["criterion = None\n","optimizer = None"]},{"cell_type":"markdown","source":["Utilisez la fonction `fit` pour entraîner le modèle."],"metadata":{"id":"N8CIGa9WiZXq"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3B8-aJxigwoH"},"outputs":[],"source":["model, history_train_loss_rnn, history_test_loss_rnn, history_train_metrics_rnn, history_test_metrics_rnn = None"]},{"cell_type":"markdown","source":["Visualisez les performances des trois architectures."],"metadata":{"id":"CCZ_BoYRjaS9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3-01WoGuqPN8"},"outputs":[],"source":["#plt.plot(np.arange(epoch), history_train_loss_deep, label='train loss deep')\n","plt.plot(np.arange(epoch), history_test_loss_deep, label='test loss deep')\n","#plt.plot(np.arange(epoch), history_train_loss_cnn, label='train loss cnn')\n","plt.plot(np.arange(epoch), history_test_loss_cnn, label='test loss cnn')\n","#plt.plot(np.arange(epoch), history_train_loss_rnn, label='train loss rnn')\n","plt.plot(np.arange(epoch), history_test_loss_rnn, label='test loss rnn')\n","plt.xlabel('Epochs')\n","plt.ylabel('loss')\n","plt.legend(loc='upper left')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wrsPW4sRqOBI"},"outputs":[],"source":["#plt.plot(history_train_metrics_deep, label='train accuracy deep')\n","plt.plot(history_test_metrics_deep, label='test accuracy deep')\n","#plt.plot(history_train_metrics_cnn, label='train accuracy cnn')\n","plt.plot(history_test_metrics_cnn, label='test accuracy cnn')\n","#plt.plot(history_train_metrics_rnn, label='train accuracy rnn')\n","plt.plot(history_test_metrics_rnn, label='test accuracy rnn')\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tVJ3D876quL4"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNtnCQf7Q4yuCNzHcA6wu5o"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}