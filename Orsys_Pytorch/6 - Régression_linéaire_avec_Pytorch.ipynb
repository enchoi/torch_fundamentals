{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"186v2wSiag7pZ7Z6U1DE9OQIe9BBmYXjW","timestamp":1730127767080}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vmh5qAX9HONe"},"source":["# Régression linéaire avec Pytorch\n","\n","Dans ce notebook, nous allons apprendre à utiliser Pytorch pour entraîner un modèle de régression linéaire sur le jeu de données Boston de Scikit-learn.\n","\n","L'objectif est de prédire le prix des maisons à partir de leurs caractéristiques."]},{"cell_type":"markdown","metadata":{"id":"PiOzO53zH8rP"},"source":["## Importation des packages"]},{"cell_type":"code","source":["!pip install scikit-learn==1.1"],"metadata":{"id":"ICcFSrY0bU7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVBa_RpuGyHU"},"source":["from sklearn.datasets import load_boston\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.preprocessing import StandardScaler\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torchsummary import summary"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3mkfIMdaIBhj"},"source":["## Importation des données"]},{"cell_type":"code","source":["boston = load_boston()\n","X = pd.DataFrame(data=boston['data'], columns=boston['feature_names'])"],"metadata":{"id":"In_VmNQvaZOd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Séparation du jeu d'entraînement et du jeu de test"],"metadata":{"id":"fg1amRUMaVVv"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, boston['target'], test_size=0.33, random_state=42)"],"metadata":{"id":"MDEie7FwavLn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Normalisation du jeu de données"],"metadata":{"id":"rK0x9yVDaw0i"}},{"cell_type":"code","source":["std_scaler = StandardScaler().fit(X_train, y_train)\n","\n","X_train  =  std_scaler.transform(X_train)\n","X_test = std_scaler.transform(X_test)"],"metadata":{"id":"bCeTIKAKaz-h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Passage de Numpy à Pytorch"],"metadata":{"id":"szY4FS1meVBv"}},{"cell_type":"code","source":["x_train_torch = torch.from_numpy(X_train).to(torch.float32)\n","x_test_torch = torch.from_numpy(X_test).to(torch.float32)\n","\n","y_train_torch = torch.from_numpy(y_train.reshape(-1, 1)).to(torch.float32)\n","y_test_torch = torch.from_numpy(y_test.reshape(-1, 1)).to(torch.float32)"],"metadata":{"id":"r6nNh5SYeYb5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dszlQ3tGJ1ZD"},"source":["## Création de l'architecture"]},{"cell_type":"markdown","metadata":{"id":"YPRWdvgoKMzY"},"source":["La fonction `Linear` permet d'initialiser les poids pour la régression linéaire et d'effectuer une multiplication matricielle entre les poids et les exemples d'entraînement. Utilisez les paramètres `in_features` et `out_features` pour spécifier le nombre d'entrées et de sorties de la couche.\n","\n","Pour plus d'informatons, n'hésitez pas à lire la [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n","\n","La fonction `Linear` sera déclarée dans un modèle via la fonction `Sequential`.\n","\n","Pour plus d'informatons, n'hésitez pas à lire la [documentation](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n"]},{"cell_type":"code","metadata":{"id":"EBW5KYGZKDeZ"},"source":["def linear_regression(input_shape:int, output_shape:int)->torch.nn.Sequential:\n","  \"\"\"\n","  Creates a simple linear regression model in PyTorch.\n","\n","  This function initializes a linear regression model with a single linear layer.\n","  The linear layer applies an affine transformation to the input data, mapping\n","  from an input space of dimension `input_shape` to an output space of dimension `output_shape`.\n","\n","  Args:\n","      input_shape (int): Number of input features (size of the input layer).\n","      output_shape (int): Number of desired outputs (size of the output layer).\n","\n","  Returns:\n","      torch.nn.Sequential: A PyTorch model containing the specified linear layer.\n","  \"\"\"\n","  model = None\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XH8SMd4JLuHJ"},"source":["Initialiser notre modèle en utilisant la fonction précédente `linear_regression`"]},{"cell_type":"code","metadata":{"id":"Raa4Xv5-LwIg"},"source":["rl_model = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la fonction `print` pour visualiser l'architecture du modèle."],"metadata":{"id":"KfNqhEUpdfFH"}},{"cell_type":"code","source":["None"],"metadata":{"id":"JLmT81jlz7xY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la fonction `summary` pour obtenir une visualisation de meilleur qualité.\n","\n","Aidez-vous de la [doc](https://pypi.org/project/torch-summary/)"],"metadata":{"id":"O_D4URYxcIy_"}},{"cell_type":"code","source":["None"],"metadata":{"id":"gcslvZCscfTV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ovbgesSnPuJz"},"source":["Prédire notre jeu d'entraînement."]},{"cell_type":"markdown","source":["Utilisez la méthode `forward` du modèle `rl_model` sur les données `x_train_torch` pour appliquer le modèle sur les données."],"metadata":{"id":"sgWiznledgAy"}},{"cell_type":"code","metadata":{"id":"XD7TNaSVPUCO"},"source":["prediction = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8_XrDMfFJ5yg"},"source":["## Définir la fonction de coût"]},{"cell_type":"markdown","metadata":{"id":"TICFolPYPzRU"},"source":["Vous allez maintenant initialiser votre fonction de coût.\n","\n","Pour ce notebook utilisez la mean absolute error qui a pour nom `L1Loss` en Pytorch.\n","\n","N'hésitez pas à lire la [documentation](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html)."]},{"cell_type":"code","metadata":{"id":"IWDG65LIQWgw"},"source":["criterion = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Appliquez la fonction de coût du nom de `criterion` pour comparer les données prédites par notre modèle `prediction` et les valeurs exactes `y_train_torch`."],"metadata":{"id":"fjYVy_ABgC2L"}},{"cell_type":"code","source":["loss = None"],"metadata":{"id":"GJ6FH8-9V-ER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UroYoaToEPit"},"source":["### Calculer les gradients"]},{"cell_type":"markdown","metadata":{"id":"z8AQ7e9EEPit"},"source":["Vous allez calculer les gradients par rapport à l’erreur pour mettre à jour les poids du modèle.\n","\n","L’objectif est d’ajuster les poids afin de faire converger l’erreur vers 0."]},{"cell_type":"markdown","metadata":{"id":"VuKRpy8MEPit"},"source":["La fonction `backward` de PyTorch permet de calculer automatiquement les gradients qu'importe le graph de calcul que vous avez créé."]},{"cell_type":"markdown","metadata":{"id":"tKMdjHSxEPit"},"source":["Imaginons une matrice de paramètres *w_1* qui va être multiplier par les données *x_1*.\n","\n","On spécifie bien `requires_grad=True` pour les paramètres."]},{"cell_type":"code","metadata":{"id":"2mc0O1rxEPit"},"source":["w_1 = torch.randn([2, 1], dtype=float, requires_grad=True)\n","x_1 = torch.randn([5, 2], dtype=float)\n","y = torch.randn([5, 1], dtype=float)\n","\n","h = torch.mm(x_1, w_1)\n","print(h.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7qt8ZvHxEPit"},"source":["Calculons l'erreur de prédiction qui est l'écart entre *y* et *h*."]},{"cell_type":"code","metadata":{"id":"J8mFgfdYEPiu"},"source":["error = torch.mean(h-y)\n","print(error)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aqkl37uxEPiu"},"source":["On va maintenant calculer les gradients des poids *w_1*"]},{"cell_type":"code","metadata":{"id":"2ih79psXEPiu"},"source":["print(w_1.grad)\n","error.backward()\n","print(w_1.grad)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xJKdsVgyEPiu"},"source":["On peut voir que les gradients on été initiliasé à *None*, c'est seulement après l'utilisation de la fonction `backward` que les gradients sont calculés."]},{"cell_type":"markdown","source":["Regardons ce que ça donne pour le modèle `rl_model`."],"metadata":{"id":"YrHhQJKihL52"}},{"cell_type":"code","source":["loss"],"metadata":{"id":"eBzPVUlAgwe7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On peut voir que la loss caculée précédemment garde des informations sur la fonction de coût et les gradients."],"metadata":{"id":"44lYb1YogvY7"}},{"cell_type":"code","source":["print(rl_model[0].weight.grad)"],"metadata":{"id":"RQs7Qwreg7O4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pour le moment le modèle ne contient aucun gradient."],"metadata":{"id":"ULd0eWODg5Gu"}},{"cell_type":"markdown","source":["Utilisez la méthode `backward` du coût `loss` pour calculer les gradients du modèle `rl_model`."],"metadata":{"id":"2XaFumyLhUVd"}},{"cell_type":"code","metadata":{"id":"_kYm_NdkEPiu"},"source":["None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Observez les gradients ainsi obtenus."],"metadata":{"id":"P39dgPM1hlmC"}},{"cell_type":"code","source":["print(rl_model[0].weight.grad)"],"metadata":{"id":"YiyMdfRYhmn_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZeeBD4bRh5sH"},"source":["### Optimiser les paramètres du modèle"]},{"cell_type":"markdown","metadata":{"id":"iHJvvdhtEPiu"},"source":["Maintenant que vous avez calculé vos gradients il va falloir mettre à jour les paramètres du modèle.\n","\n","Il existe de nombreux algorithmes d'optimisation, ici on va rester simple en utilisant celui du Stochastic Gradient Descent `SGD`.\n","\n","Vous allez d'abord initialiser l'algorithme d'optimisation avec la fonction `SGD` en paramètre il faudra lui donner les paramètres du modèle `rl_model` avec la méthode `parameters` et un learning rate `lr` de 0.3.\n","\n","N'hésitez pas à regarder la [documentation](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)"]},{"cell_type":"code","metadata":{"id":"xz5Kv3TbEPiv"},"source":["optimizer = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Regardez les valeurs des paramètres du modèle."],"metadata":{"id":"jse0h3Zyihou"}},{"cell_type":"code","metadata":{"id":"bUg25te1EPiv"},"source":["print(rl_model[0].weight)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Regardez les gradients de chaque paramètre."],"metadata":{"id":"qLBO1dYWikrG"}},{"cell_type":"code","metadata":{"id":"p6gjXYuEEPiv"},"source":["print(rl_model[0].weight.grad)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculez le coût du modèle à ce stade."],"metadata":{"id":"GjaONZmEioZz"}},{"cell_type":"code","source":["loss"],"metadata":{"id":"dPf0alXLitCQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la méthode `step` de l'algorithme d'optimisation `optimizer` afin de mettre à jour les paramètres du modèle en utilisant l'algorithme du gradient descent en utilisant les gradients précédemment calculé."],"metadata":{"id":"ewotH5lOit9o"}},{"cell_type":"code","metadata":{"id":"CHBqM49jEPiv"},"source":["None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Regardez les nouvelles valeurs des paramètres du modèle."],"metadata":{"id":"KgAMqITWi7zj"}},{"cell_type":"code","metadata":{"id":"19xyP5A-EPiv"},"source":["print(rl_model[0].weight)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez la méthode `forward` pour prédire les données avec les nouveaux paramètres du modèle."],"metadata":{"id":"vNe3eMgKjMDO"}},{"cell_type":"code","source":["prediction = None"],"metadata":{"id":"YH-b3FaVjEaJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Utilisez `criterion` pour calculer le coût du modèle avec les nouveaux paramètres."],"metadata":{"id":"Us7Rl2KYjSVe"}},{"cell_type":"code","source":["None"],"metadata":{"id":"rC6Pq-pcjXse"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On observe qu'avec les nouveaux paramètres, le coût est inférieur au précédent.\n","\n","Le modèle converge donc vers un ensemble de paramètres qui minimise l'erreur de prédiction."],"metadata":{"id":"LvS2QD9njX6m"}},{"cell_type":"markdown","metadata":{"id":"YA6hWkeEJ_ds"},"source":["## Définir la fonction d'entraînement"]},{"cell_type":"markdown","metadata":{"id":"hT8eCpUaSLxz"},"source":["Vous allez maintenant initialiser la fonction d'entraînement du modèle en utilisant le modèle, la fonction de coût et l'algorithme d'optimisation précédemment initialisé."]},{"cell_type":"code","metadata":{"id":"c5iq3weNI2-l"},"source":["def step(model:torch.nn.Sequential,\n","         opt:torch.optim,\n","         loss:torch.nn.modules.loss,\n","         x_train:torch.Tensor,\n","         y_train:torch.Tensor)->tuple:\n","  \"\"\"\n","  Executes a single training step for a PyTorch model.\n","  This function performs a forward pass to compute the model's predictions, calculates\n","  the loss between predictions and actual target values, computes gradients for each\n","  model parameter, and updates the parameters using the optimizer.\n","\n","  Args:\n","      model (torch.nn.Sequential): The PyTorch model to train.\n","      optimizer (torch.optim.Optimizer): Optimizer used to update the model's parameters.\n","      criterion (torch.nn.modules.loss._Loss): Loss function used to compute the error.\n","      x_train (torch.Tensor): Input training data (features).\n","      y_train (torch.Tensor): Ground truth labels or target values for the training data.\n","  Returns:\n","      tuple: The updated model and the computed loss for the current step.\n","  \"\"\"\n","\n","  # Réinitialisez les gradients d'optimizer à zéro avec la méthode 'zero_grad'\n","  None\n","\n","  # Calculez les prédiction sur le jeu d'entraînement avec la méthode 'froward'\n","  prediction = None\n","\n","  # Calculez l'erreur de prédiction avec 'criterion'\n","  loss = None\n","\n","  # Calculez les gradients avec la méthode 'backward'\n","  None\n","\n","  # Mettre à jour les paramètres du modèle avec la méthode 'step'\n","  None\n","\n","  return model, loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eP17TJdcTbAT"},"source":["## Entraîner le modèle"]},{"cell_type":"markdown","metadata":{"id":"CDLHMZXrTdGO"},"source":["Il est maintenant temps d'entraîner le modèle\n","\n"]},{"cell_type":"code","metadata":{"id":"b9Fl1-rsTKw9"},"source":["epoch = 1000\n","history_train = []\n","history_test = []\n","\n","for e in range(epoch) :\n","\n","  # mise à jour des poids avec la fonction 'step'\n","  rl_model, train_loss = None\n","\n","  # prédiction sur le jeu de test avec la méthode 'foward'\n","  test_pred = None\n","\n","  # Calculer l'erreur de prédiction sur le jeu de test avec 'criterion'\n","  test_loss = None\n","\n","  # Sauvegarde des coûts d'entraînement de l'entraînement et du jeu de test avec append\n","  history_train = None\n","  history_test = None\n","\n","  print('train_loss : '+str(np.squeeze(train_loss.detach().numpy()))+ ' test_loss : '+str(test_loss.detach().numpy()))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2u32IQUdYX-4"},"source":["Visualisation de l'évolution du coût pendant l'entraînement."]},{"cell_type":"code","metadata":{"id":"03l20groTpLh"},"source":["plt.plot(np.arange(epoch), history_train, label='train loss')\n","plt.plot(np.arange(epoch), history_test, label='test loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('MAE')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3pKkixYFY1qd"},"source":["## Sauvegarde du modèle"]},{"cell_type":"markdown","metadata":{"id":"mM_7mFShZ906"},"source":["Maintenant que le modèle est entraîné, il est temps de le sauvegarder."]},{"cell_type":"markdown","source":["Sauvegardez les poids du modèle grâce à la méthode `save`.\n","\n","N'hésitez pas à vous aider de la [documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"],"metadata":{"id":"YUoF8P2aiSsC"}},{"cell_type":"code","source":["None"],"metadata":{"id":"UrqYDKQvlqKI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jseO56VGaDeV"},"source":["Remplacez le modèle entraîné par un nouveau modèle dont les poids sont initialisés aléatoirement."]},{"cell_type":"code","metadata":{"id":"4zgfnYkWZh4z"},"source":["rl_model = linear_regression(input_shape=13, output_shape=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculez la performance de ce modèle."],"metadata":{"id":"aneouhUZobor"}},{"cell_type":"code","metadata":{"id":"0I2c9GpfZpWc"},"source":["prediction = rl_model(x_train_torch)\n","criterion(prediction, y_train_torch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comme les paramètres du modèle sont initialisés aléatoirement, les performances sont faibles."],"metadata":{"id":"Np-F09gxh_Kl"}},{"cell_type":"markdown","metadata":{"id":"C92sBoBvaJuW"},"source":["Nous pouvons restaurer nos poids entraînés en chargeant les poids précédemment sauvegardés.\n","\n","En utilisant la méthode `load_state_dict`.\n","\n","Aidez-vous de la [documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"]},{"cell_type":"code","metadata":{"id":"64FFwodfZZGc"},"source":["None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T7E-voudZqoy"},"source":["prediction = rl_model.forward(x_train_torch)\n","criterion(prediction, y_train_torch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Maintenant que les paramètres du modèle entraîné sont chargés, ses performances sont identiques au précédent modèle."],"metadata":{"id":"AfCACAbDh8aV"}},{"cell_type":"code","source":[],"metadata":{"id":"k5GScsdMo69t"},"execution_count":null,"outputs":[]}]}